<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Ykk</title>
  
  <subtitle>Carpe diem</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://ykksmile.top/"/>
  <updated>2018-11-20T10:42:54.879Z</updated>
  <id>https://ykksmile.top/</id>
  
  <author>
    <name>Ykk</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>华为云GES服务图引擎中的实时推荐算法</title>
    <link href="https://ykksmile.top/posts/3788/"/>
    <id>https://ykksmile.top/posts/3788/</id>
    <published>2018-11-20T08:03:45.000Z</published>
    <updated>2018-11-20T10:42:54.879Z</updated>
    
    <content type="html"><![CDATA[<p>参加了华为EI学习训练营，记录在华为云GES中实施推荐算法参数的实验。</p><a id="more"></a><hr><h2 id="GES实时推荐算法学习"><a href="#GES实时推荐算法学习" class="headerlink" title="GES实时推荐算法学习"></a>GES实时推荐算法学习</h2><p>使用提供的training-data数据，其中包括<br>算法包括的参数有sources,alpha,N,nv,np,label,directed，下面分参数进行分析（未提到的参数皆设置为默认值）：</p><h3 id="sources"><a href="#sources" class="headerlink" title="sources"></a>sources</h3><p>节点ID，最大数量为30，可以选择各种类型，在本例中，例如导演、电影等。</p><h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><p>以sources=Leo，label=user为例，为Leo推荐用户：</p><p><img src="https://blog-1252404748.cos.ap-chengdu.myqcloud.com/huawei-AI/sources-1.png" alt="sources-1"></p><pre><code>{&quot;sources&quot;: [    &quot;Leo&quot;],&quot;runtime&quot;: 0.072342,&quot;results&quot;: [    {        &quot;score&quot;: 1679.9999999999998,        &quot;id&quot;: &quot;Leo&quot;    },    {        &quot;score&quot;: 168,        &quot;id&quot;: &quot;Evan&quot;    },    {        &quot;score&quot;: 151,        &quot;id&quot;: &quot;Neil&quot;    },</code></pre><p>可发现与Leo距离最近的用户为Evan，得分为168，第二为Neil，得分151：</p><p>在ID中加入Evan，为Leo和Evan同时推荐用户，运行时间基本没变，Neil的得分增加为263： </p><p><img src="https://blog-1252404748.cos.ap-chengdu.myqcloud.com/huawei-AI/sources-2.png" alt="sources-2"></p><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><ul><li>实时推荐系统基于随机游走算法，score得分的计算可能基于用户的信任关系以及各节点的相似度计算，得分越高说明相关度越高。</li><li>选择不同的source可以达到不同的推荐效果，sources可以选择类型不同的节点，例如用户、电影名称、导演名称等，可以根据用户喜好和用户路径为其推荐任意label的节点。</li></ul><hr><h3 id="alpha"><a href="#alpha" class="headerlink" title="alpha"></a>alpha</h3><p>权重系数，0-1，系数越大，步长越长。</p><h4 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h4><p>固定其他变量，调整alpha，注意观测运行时间和查询结果。</p><p>alpha = 0.2：<br><img src="https://blog-1252404748.cos.ap-chengdu.myqcloud.com/huawei-AI/alpha-0.2.png" alt="alpha-0.2"></p><p>alpha = 0.5:<br><img src="https://blog-1252404748.cos.ap-chengdu.myqcloud.com/huawei-AI/alpha-0.5.png" alt="alpha-0.5"></p><p>alpha = 0.85:<br><img src="https://blog-1252404748.cos.ap-chengdu.myqcloud.com/huawei-AI/alpha-0.85.png" alt="alpha-0.85"></p><h4 id="结论-1"><a href="#结论-1" class="headerlink" title="结论"></a>结论</h4><ul><li>alpha越大，步长越长，算法运行时间越短，合理的增加步长有利于减少计算资源占用，缩短预测时间；</li><li>alpha越大，Leo的score越低，并且出现不同的推荐结果，理论上，步长越小，结果越精确。</li></ul><hr><h2 id="N"><a href="#N" class="headerlink" title="N"></a>N</h2><p>游走步数，[1,200000]。</p><h3 id="实验-2"><a href="#实验-2" class="headerlink" title="实验"></a>实验</h3><p>N = 10000：</p><p><img src="https://blog-1252404748.cos.ap-chengdu.myqcloud.com/huawei-AI/alpha-0.85.png" alt="N-10000"></p><p>N = 100000：</p><p><img src="https://blog-1252404748.cos.ap-chengdu.myqcloud.com/huawei-AI/N-100000.png" alt="N-100000"></p><p>N = 200000：</p><p><img src="https://blog-1252404748.cos.ap-chengdu.myqcloud.com/huawei-AI/N-200000.png" alt="N-200000"></p><h3 id="结论-2"><a href="#结论-2" class="headerlink" title="结论"></a>结论</h3><p>随着游走步数N的增加，算法运行时长增加，节点score增加，可以猜测，对于固定边和点的图，当N达到一定步数时，即得到全局最优解，合理的设置游走步数N可以节约计算资源。</p><hr><h2 id="nv-np"><a href="#nv-np" class="headerlink" title="nv np"></a>nv np</h2><p>随机游走提前结束参数，当候选节点被访问次数达到nv或者候选节点个数达到np时，候选节点加入推荐。</p><h3 id="实验-3"><a href="#实验-3" class="headerlink" title="实验"></a>实验</h3><p>nv - np  5 - 100:</p><p><img src="https://blog-1252404748.cos.ap-chengdu.myqcloud.com/huawei-AI/nv5-100.png" alt="5-100"></p><p>nv - np  5 - 1000:</p><p><img src="https://blog-1252404748.cos.ap-chengdu.myqcloud.com/huawei-AI/nv5-1000.png" alt="5-1000"></p><p>nv - np  2 - 100:</p><p><img src="https://blog-1252404748.cos.ap-chengdu.myqcloud.com/huawei-AI/nv2-100.png" alt="2-100"></p><p>nv - np  2 - 1000:</p><p><img src="https://blog-1252404748.cos.ap-chengdu.myqcloud.com/huawei-AI/nv2-1000.png" alt="2-1000"></p><h3 id="结论-3"><a href="#结论-3" class="headerlink" title="结论"></a>结论</h3><ul><li>随着nv的增加，运行时间增加，节点的得分score增加，可见当访问次数达到nv，节点将加入推荐，这将提前结束游走算法。</li><li>随着np的增加，运行时间增加，节点的得分score增加，同样可见当访问次数达到nv，节点将加入推荐，这将提前结束游走算法。</li><li>类似神经网络中的dropout，选择合适的nv和np可以减少计算量，更快的得到需要的结果。</li></ul><hr><h2 id="directed"><a href="#directed" class="headerlink" title="directed"></a>directed</h2><p>是否考虑图的边的方向。</p><h3 id="实验-4"><a href="#实验-4" class="headerlink" title="实验"></a>实验</h3><p>True：</p><p><img src="https://blog-1252404748.cos.ap-chengdu.myqcloud.com/huawei-AI/true.png" alt="true"></p><p>False：</p><p><img src="https://blog-1252404748.cos.ap-chengdu.myqcloud.com/huawei-AI/false.png" alt="false"></p><h3 id="结论-4"><a href="#结论-4" class="headerlink" title="结论"></a>结论</h3><p>考虑边的方向后，实际上限制了随机游走算法，计算复杂度降低，计算时间减少，</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参加了华为EI学习训练营，记录在华为云GES中实施推荐算法参数的实验。&lt;/p&gt;
    
    </summary>
    
      <category term="Notes" scheme="https://ykksmile.top/categories/Notes/"/>
    
      <category term="比赛" scheme="https://ykksmile.top/categories/Notes/%E6%AF%94%E8%B5%9B/"/>
    
    
      <category term="算法" scheme="https://ykksmile.top/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>十个机器学习高频面试问题</title>
    <link href="https://ykksmile.top/posts/32025/"/>
    <id>https://ykksmile.top/posts/32025/</id>
    <published>2018-10-25T13:47:35.000Z</published>
    <updated>2018-10-30T08:49:39.688Z</updated>
    
    <content type="html"><![CDATA[<p>总结十个机器学习高频面试问题。</p><a id="more"></a><hr><h2 id="偏差与方差"><a href="#偏差与方差" class="headerlink" title="偏差与方差"></a>偏差与方差</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>偏差： 衡量预测的期望值和真实值的差<br>方差： 衡量预测的期望值和预测值的差平方和</p><p>Err = Bias^2 + Variance + 噪声</p><p>偏差描述拟合能力，方差描述模型的稳定性</p><p>导致偏差的是模型错误的假设，导致方差的是模型的复杂度相对于训练集过高</p><h3 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h3><p>拟合能力强，训练误差小，方差较大，降低泛化误差——正则化方法</p><h3 id="偏差与方差的权衡"><a href="#偏差与方差的权衡" class="headerlink" title="偏差与方差的权衡"></a>偏差与方差的权衡</h3><ul><li>训练不足 你和能力不够 偏差主导</li><li>拟合能力增强  方差主导</li><li>过拟合</li></ul><hr><h2 id="生成模型与判别模型"><a href="#生成模型与判别模型" class="headerlink" title="生成模型与判别模型"></a>生成模型与判别模型</h2><h3 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h3><ul><li>判别模型直接学习决策函数或者条件概率分布</li><li>生成模型学习联合概率分布，然后根据条件概率公式计算</li></ul><h3 id="联系"><a href="#联系" class="headerlink" title="联系"></a>联系</h3><ul><li>生成模型可以得到判别模型，反之不可以</li><li>存在隐变量时，只能使用生成模型</li></ul><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>判别模型：</p><ul><li>优点： 直接预测，准确率高； 对数据抽象，可以使用特征简化学习过程</li><li>缺点： 不能反映数据本身特性</li></ul><p>生成模型：</p><ul><li>可以反映联合概率分布</li><li>学习收敛速度快</li><li>存在隐变量也可以使用</li><li>缺点： 学习和计算比较复杂</li></ul><h3 id="常见模型"><a href="#常见模型" class="headerlink" title="常见模型"></a>常见模型</h3><ul><li>判别模型： K近邻 感知机 决策树 LR 最大熵 SVM boost 条件随机场</li><li>生成模型： 朴素贝叶斯 隐马尔科夫 混合高斯 贝叶斯 马尔科夫随机场</li></ul><hr><h2 id="先验概率和后验概率"><a href="#先验概率和后验概率" class="headerlink" title="先验概率和后验概率"></a>先验概率和后验概率</h2><p><strong>垃圾邮件分类器</strong></p><ol><li>先验概率 P(S) P(H) 0.5</li><li>一个词语的后验概率p(S|W)</li><li>15个垃圾邮件概率最高的词，求联合概率P</li><li>设置阈值 P&gt;0.9认为垃圾</li></ol><p><img src="http://blog.chinaunix.net/attachment/201308/18/26548237_1376792734Zfd8.png" alt="此处输入图片的描述"></p><ul><li>先验概率：<br>  事件发生前的预判概率。可以是基于历史数据的统计，可以由背景常识得出，也可以是人的主观观点给出     一般都是单独事件概率，如P(x),P(y)。</li><li>后验概率：<br>  事件发生后求的反向条件概率；或者说，基于先验概率求得的反向条件概率。概率形式与条件概率相同。<br>  条件概率：<br>  一个事件发生后另一个事件发生的概率。一般的形式为P(x|y)表示y发生的条件下x发生的概率。</li></ul><p>贝叶斯公式求条件概率：</p><pre><code>P(y|x) = ( P(x|y) * P(y) ) /P(x)</code></pre><p>最大似然理论： 认为P(X|Y)最大的类别Y，就是当前文档所属类别</p><hr><h2 id="超参数选择"><a href="#超参数选择" class="headerlink" title="超参数选择"></a>超参数选择</h2><h3 id="Grid-Search"><a href="#Grid-Search" class="headerlink" title="Grid Search"></a>Grid Search</h3><p>穷举搜索，所有候选参数尝试：</p><p>设置训练集，验证集，测试集 —— 验证集用来调参</p><ul><li>网格搜索</li><li>高维空间中对一定区域遍历</li></ul><h3 id="Random-Search"><a href="#Random-Search" class="headerlink" title="Random Search"></a>Random Search</h3><ul><li>高维空间中随机选择若干参数</li></ul><hr><h2 id="余弦相似度（Cos距离）与欧氏距离的区别和联系"><a href="#余弦相似度（Cos距离）与欧氏距离的区别和联系" class="headerlink" title="余弦相似度（Cos距离）与欧氏距离的区别和联系"></a>余弦相似度（Cos距离）与欧氏距离的区别和联系</h2><ol><li>欧式距离和余弦相似度都能度量 2 个向量之间的相似度</li><li>放到向量空间中看，欧式距离衡量两点之间的直线距离，而余弦相似度计算的是两个向量之间的夹角</li><li>没有归一化时，欧式距离的范围是 (0, +∞]，而余弦相似度的范围是 (0, 1]；余弦距离是计算相似程度，而欧氏距离计算的是相同程度（对应值的相同程度）</li><li>归一化的情况下，可以将空间想象成一个超球面（三维），欧氏距离就是球面上两点的直线距离，而向量余弦值等价于两点的球面距离，本质是一样。</li></ol><hr><h2 id="混淆矩阵、模型度量指标：准确率、精确率、召回率、F1-值等"><a href="#混淆矩阵、模型度量指标：准确率、精确率、召回率、F1-值等" class="headerlink" title="混淆矩阵、模型度量指标：准确率、精确率、召回率、F1 值等"></a>混淆矩阵、模型度量指标：准确率、精确率、召回率、F1 值等</h2><p>准确率 ACC = TP+TN/TP+FN+TN+FP<br>精确率 precision = TP/TP+FP<br>召回率 recall = TP/TP+FN<br>F1  精确率和召回率的调和均值 2/F = 1/P+1/R</p><hr><h2 id="如何处理数据中的缺失值"><a href="#如何处理数据中的缺失值" class="headerlink" title="如何处理数据中的缺失值"></a>如何处理数据中的缺失值</h2><ol><li>缺失值较多，舍弃</li><li>缺失值较少，填充<ul><li>异常值填充</li><li>均值</li><li>相邻数据</li><li>插值</li><li>拟合</li></ul></li></ol><hr><h2 id="关联规则挖掘的-3-个度量指标：支持度、置信度、提升度"><a href="#关联规则挖掘的-3-个度量指标：支持度、置信度、提升度" class="headerlink" title="关联规则挖掘的 3 个度量指标：支持度、置信度、提升度"></a>关联规则挖掘的 3 个度量指标：支持度、置信度、提升度</h2><ul><li>支持度</li><li>置信度</li><li>提升度</li></ul><hr><h2 id="信息量，信息熵，交叉熵，KL散度和互信息（信息增益）"><a href="#信息量，信息熵，交叉熵，KL散度和互信息（信息增益）" class="headerlink" title="信息量，信息熵，交叉熵，KL散度和互信息（信息增益）"></a>信息量，信息熵，交叉熵，KL散度和互信息（信息增益）</h2><p>K-L散度：</p><ul><li>非负 PQ相同分布，KL散度为0</li><li>不对称</li></ul><p>针对 Q 最小化交叉熵等价于最小化 P 对 Q 的 KL 散度，因为 Q 并不参与被省略的那一项。</p><p>最大似然估计中，最小化 KL 散度其实就是在最小化分布之间的交叉熵。</p><hr><h2 id="logistic回归"><a href="#logistic回归" class="headerlink" title="logistic回归"></a>logistic回归</h2><h3 id="推导"><a href="#推导" class="headerlink" title="推导"></a>推导</h3><p>负对数函数作为损失，极大似然法，最大化对数函数</p><hr><h2 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h2><h3 id="推导-1"><a href="#推导-1" class="headerlink" title="推导"></a>推导</h3><p>SMO  选取违背KKT条件最大的一对ai aj 固定a 求其他参数 更新a</p><h3 id="最大间隔超平面背后的原理"><a href="#最大间隔超平面背后的原理" class="headerlink" title="最大间隔超平面背后的原理"></a>最大间隔超平面背后的原理</h3><ul><li>相当于在最小化权重时对训练误差进行了约束——对比 L2 范数正则化，则是在最小化训练误差时，对权重进行约束</li><li>相当于限制了模型复杂度——在一定程度上防止过拟合，具有更强的泛化能力</li></ul><p><img src="https://raw.githubusercontent.com/imhuay/Algorithm_Interview_Notes-Chinese/master/_assets/TIM%E6%88%AA%E5%9B%BE20180710112848.png" alt="与L2相比"></p><hr><h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><h3 id="ID3-C4-5"><a href="#ID3-C4-5" class="headerlink" title="ID3 C4.5"></a>ID3 C4.5</h3><p>前者使用信息增益来进行特征选择，而后者使用信息增益比。</p><h3 id="CART"><a href="#CART" class="headerlink" title="CART"></a>CART</h3><p>回归树使用平方误差最小化，分类使用基尼指数最小化</p><hr><h2 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h2><h3 id="boosting"><a href="#boosting" class="headerlink" title="boosting"></a>boosting</h3><p>Boosting（提升）方法从某个基学习器出发，反复学习，得到一系列基学习器，然后组合它们构成一个强学习器。</p><h4 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h4><p><strong>推导</strong></p><ol><li>初始化权值分布</li><li>基分类器，计算分类误差em</li><li>计算权值分布的系数 am ——用于加权表决</li><li>更新训练集权值分布</li><li>构建基学习器的线性组合</li></ol><ol><li>每一轮如何改变数据的权值或概率分布？——开始时，每个样本的权值是一样的，AdaBoost 的做法是提高上一轮弱分类器错误分类样本的权值，同时降低那些被正确分类样本的权值。</li><li>如何将弱分类器组合成一个强分类器？—— AdaBoost 采取加权表决的方法（加法模型am）。具体的，AdaBoost 会加大分类误差率小的基学习器的权值，使其在表决中起到更大的作用，同时减小分类误差率大的基学习器的权值。</li></ol><p>算法要点：</p><pre><code>开始时，训练集中所有数据具有均匀的权值分布计算分类误差率，实际上就是计算所有分类错误的数据的权值之和G_m(x) 的系数 α_m 表示该学习器在最终学习器中的重要性；公式 表明当分类错误率 e_m &lt;= 1/2 时，α_m &gt;= 0，并且 α_m 随 e_m 的减小而增大被基分类器分类错误的样本权值会扩大，而分类正确的权值会缩小——不改变训练数据，而不断改变训练数据权值的分布，使训练数据在基学习器的学习中起到不同的作用，这是 AdaBoost 的一个特点。</code></pre><p>是一种特殊的前向分步算法</p><h4 id="提升树-boosting-tree"><a href="#提升树-boosting-tree" class="headerlink" title="提升树 boosting tree"></a>提升树 boosting tree</h4><ul><li>以决策树为基学习器，对分类问题使用二叉分类树，回归问题使用二叉回归树。</li><li>解决回归问题时，通过不断拟合残差得到新的树。</li><li>提升树模型可表示为决策树的加法模型</li><li>然后通过最小化损失函数决定下一个决策树的参数</li><li>对于二分类问题，提升树算法只需要将AdaBoost 算法中的基学习器限制为二叉分类树即可</li></ul><h4 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h4><ul><li>GBDT 是以决策树为基学习器、采用 Boosting 策略的一种集成学习模型</li><li>与提升树的区别：残差的计算不同，提升树使用的是真正的残差，梯度提升树用当前模型的负梯度来拟合残差。</li></ul><h4 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h4><ol><li>定义一棵树</li><li>对损失函数加入正则项，包括L2权重衰减和对叶子数限制</li><li>使用牛顿法代替梯度下降法  —— 前者使用一阶+二阶导数作为残差，后者只使用了一阶导数</li><li>传统 CART树寻找最优切分点的标准是最小化均方差；XGBoost 通过最大化得分公式来寻找最优切分点</li></ol><p><strong>XGBoost 的一些内部优化</strong></p><ul><li>在寻找最佳分割点时，传统的方法会枚举每个特征的所有可能切分点。XGBoost 实现了一种近似的算法，大致的思想是根据百分位法列举几个可能成为分割点的候选者，然后从候选者中根据上面求分割点的公式计算找出最佳的分割点。</li><li>XGBoost 考虑了训练数据为稀疏值的情况，可以为缺失值或者指定的值指定分支的默认方向，这能大大提升算法的效率，paper 提到能提高 50 倍。</li><li>特征列排序后以块的形式存储在内存中，在迭代中可以重复使用；虽然 Boosting 算法迭代必须串行，但是在处理每个特征列时可以做到并行。</li><li>按照特征列方式存储能优化寻找最佳的分割点，但是当以行计算梯度数据时会导致内存的不连续访问，严重时会导致 cache miss，降低算法效率。Paper 中提到，可先将数据收集到线程内部的 buffer，然后再计算，提高算法的效率。</li><li>XGBoost 还考虑了数据量比较大的情况，当内存不够时怎么有效的使用磁盘，主要是结合多线程、数据压缩、分片的方法，尽可能的提高算法的效率。</li></ul><h3 id="bagging"><a href="#bagging" class="headerlink" title="bagging"></a>bagging</h3><p>基于并行策略：基学习器之间不存在依赖关系，可同时生成。</p><ul><li>利用自助采样法对训练集随机采样，重复进行 T 次;</li><li>基于每个采样集训练一个基学习器，并得到 T 个基学习器；</li><li>预测时，集体投票决策。 </li><li>自助采样法：对 m 个样本的训练集，有放回的采样 m 次；此时，样本在 m 次采样中始终没被采样的概率约为 0.368 （1/e），即每次自助采样只能采样到全部样本的 63% 左右。</li></ul><h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><h4 id="stacking"><a href="#stacking" class="headerlink" title="stacking"></a>stacking</h4><p>基于串行策略：初级学习器与次级学习器之间存在依赖关系，初学习器的输出作为次级学习器的输入。</p><ul><li>先从初始训练集训练 T 个不同的初级学习器;</li><li>利用每个初级学习器的输出构建一个次级数据集，该数据集依然使用初始数据集的标签；</li><li>根据新的数据集训练次级学习器；</li><li>多级学习器的构建过程类似。</li><li><p>为了降低过拟合的风险，一般会利用交叉验证的方法使不同的初级学习器在不完全相同的子集上训练 </p><p>  以 k-折交叉验证为例：</p><ul><li>初始训练集 D={(x_i, y_i)} 被划分成 D1, D2, .., Dk；</li><li>记 h_t 表示第 t 个学习器，并在除 Dj 外的数据上训练；</li><li>当 h_t 训练完毕后，有 z_it = h_t(x_i)；</li><li>T 个初级学习器在 x_i 上共产生 T 个输出；</li><li>这 T 个输出共同构成第 i 个次级训练数据 z_i = (z_i1, z_i2, …, z_iT)，标签依然为 y_i；</li><li>在 T 个初级学习器都训练完毕后，得到次级训练集 D’={(z_i, y_i)}</li></ul></li></ul><h3 id="为什么使用决策树作为基学习器？"><a href="#为什么使用决策树作为基学习器？" class="headerlink" title="为什么使用决策树作为基学习器？"></a>为什么使用决策树作为基学习器？</h3><p>(1). 决策树的表达能力和泛化能力，可以通过剪枝快速调整；<br>(2). 决策树可以方便地将<strong>样本的权重</strong>整合到训练过程中；  （boosting<br>(3). 决策树是一种<strong>不稳定</strong>的学习器；  （bagging<br>     所谓不稳定，指的是数据样本的扰动会对决策树的结果产生较大的影响；</p><h3 id="为什么不稳定的学习器更适合作为基学习器？"><a href="#为什么不稳定的学习器更适合作为基学习器？" class="headerlink" title="为什么不稳定的学习器更适合作为基学习器？"></a>为什么不稳定的学习器更适合作为基学习器？</h3><ul><li>不稳定的学习器容易受到样本分布的影响（方差大），很好的引入了随机性；这有助于在集成学习（特别是采用 Bagging 策略）中提升模型的泛化能力。</li><li>为了更好的引入随机性，有时会随机选择一个属性子集中的最优分裂属性，而不是全局最优（随机森林）</li></ul><h3 id="Boosting-Bagging-与-偏差-方差-的关系"><a href="#Boosting-Bagging-与-偏差-方差-的关系" class="headerlink" title="Boosting/Bagging 与 偏差/方差 的关系"></a>Boosting/Bagging 与 偏差/方差 的关系</h3><p>简单来说，Boosting 能提升弱分类器性能的原因是降低了偏差；Bagging 则是降低了方差；</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;总结十个机器学习高频面试问题。&lt;/p&gt;
    
    </summary>
    
      <category term="就业" scheme="https://ykksmile.top/categories/%E5%B0%B1%E4%B8%9A/"/>
    
    
      <category term="MachineLearning" scheme="https://ykksmile.top/tags/MachineLearning/"/>
    
      <category term="DeepLearning" scheme="https://ykksmile.top/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>十个图像处理处理高频面试问题</title>
    <link href="https://ykksmile.top/posts/46360/"/>
    <id>https://ykksmile.top/posts/46360/</id>
    <published>2018-10-25T13:47:35.000Z</published>
    <updated>2018-10-31T11:36:27.133Z</updated>
    
    <content type="html"><![CDATA[<p>总结十个图像处理处理高频面试问题。<br><a id="more"></a></p><hr><h2 id="图像特征-HOG-LBP-Haar"><a href="#图像特征-HOG-LBP-Haar" class="headerlink" title="图像特征 HOG LBP Haar"></a>图像特征 HOG LBP Haar</h2><h3 id="HOG特征"><a href="#HOG特征" class="headerlink" title="HOG特征"></a>HOG特征</h3><p>行人检测 HOG+SVM</p><p>在一副图像中，局部目标的表象和形状（appearance and shape）能够被梯度或边缘的方向密度分布很好地描述。</p><p>本质：梯度主要存在于边缘的地方</p><p>实现方法： 首先将图像分成小的连通区域，我们把它叫细胞单元。然后采集细胞单元中各像素点的梯度的或边缘的方向直方图。最后把这些直方图组合起来就可以构成特征描述器。</p><p>过程：</p><ol><li>灰度化</li><li>Gamma校正法，颜色空间归一化</li><li>计算每个像素的梯度</li><li>图像划分为小的cell</li><li>cell的梯度直方图</li><li>几个cell组成一个block 一个block中所有cell的特征串联起来成为HOG特征</li><li>所有block的特征串联</li></ol><p>把样本图像分割为若干个像素的单元（cell），把梯度方向平均划分为9个区间（bin），在每个单元里面对所有像素的梯度方向在各个方向区间进行直方图统计，得到一个9维的特征向量，每相邻的4个单元构成一个块（block），把一个块内的特征向量联起来得到36维的特征向量，用块对样本图像进行扫描，扫描步长为一个单元。最后将所有块的特征串联起来，就得到了人体的特征。例如，对于64<em>128的图像而言，每16</em>16的像素组成一个cell，每2<em>2个cell组成一个块，因为每个cell有9个特征，所以每个块内有4</em>9=36个特征，以8个像素为步长，那么，水平方向将有7个扫描窗口，垂直方向将有15个扫描窗口。也就是说，64<em>128的图片，总共有36</em>7*15=3780个特征。</p><h3 id="LBP"><a href="#LBP" class="headerlink" title="LBP"></a>LBP</h3><p>流程：<br>以窗口中心像素为阈值，将相邻的8个像素的灰度值与其进行比较，若周围像素值大于中心像素值，则该像素点的位置被标记为1，否则为0。这样，3*3邻域内的8个点经比较可产生8位二进制数（通常转换为十进制数即LBP码，共256种），即得到该窗口中心像素点的LBP值，并用这个值来反映该区域的纹理信息。</p><p>改进：</p><ul><li>圆形LBP</li><li>LBP旋转不变</li><li>LBP等价模式</li></ul><h3 id="Haar特征"><a href="#Haar特征" class="headerlink" title="Haar特征"></a>Haar特征</h3><p>Haar特征分为三类：边缘特征、线性特征、中心特征和对角线特征，组合成特征模板。</p><h4 id="Haar-like特征的计算—积分图"><a href="#Haar-like特征的计算—积分图" class="headerlink" title="Haar-like特征的计算—积分图"></a>Haar-like特征的计算—积分图</h4><p>积分图主要的思想是将图像从起点开始到各个点所形成的矩形区域像素之和作为一个数组的元素保存在内存中，当要计算某个区域的像素和时可以直接索引数组的元素，不用重新计算这个区域的像素和，从而加快了计算（这有个相应的称呼，叫做动态规划算法）。积分图能够在多种尺度下，使用相同的时间（常数时间）来计算不同的特征，因此大大提高了检测速度。</p><hr><h2 id="边缘检测"><a href="#边缘检测" class="headerlink" title="边缘检测"></a>边缘检测</h2><h3 id="Hough霍夫变换"><a href="#Hough霍夫变换" class="headerlink" title="Hough霍夫变换"></a>Hough霍夫变换</h3><p>我们知道，一条直线在直角坐标系下可以用y=kx+b表示, 霍夫变换的主要思想是将该方程的参数和变量交换，即用x,y作为已知量k,b作为变量坐标，所以直角坐标系下的直线y=kx+b在参数空间表示为点(k,b)，而一个点(x1,y1)在直角坐标系下表示为一条直线y1=x1·k+b，其中(k,b)是该直线上的任意点。为了计算方便，我们将参数空间的坐标表示为极坐标下的γ和θ。因为同一条直线上的点对应的(γ,θ)是相同的，因此可以先将图片进行边缘检测，然后对图像上每一个非零像素点，在参数坐标下变换为一条直线，那么在直角坐标下属于同一条直线的点便在参数空间形成多条直线并内交于一点。因此可用该原理进行直线检测。</p><h3 id="一阶微分算子：Roberts-、Sobel-、Prewitt"><a href="#一阶微分算子：Roberts-、Sobel-、Prewitt" class="headerlink" title="一阶微分算子：Roberts 、Sobel 、Prewitt"></a>一阶微分算子：Roberts 、Sobel 、Prewitt</h3><p>Roberts：<br>[1 0<br> 0 -1]</p><p> Sobel:<br> [-1 -2 -1<br>   0  0  0<br>   1  2  1]</p><p> Prewitt:<br> [1   1  1<br>  0   0  0<br>  -1 -1 -1]</p><h3 id="二阶导数算子"><a href="#二阶导数算子" class="headerlink" title="二阶导数算子"></a>二阶导数算子</h3><h4 id="拉普拉斯Laplacian算子"><a href="#拉普拉斯Laplacian算子" class="headerlink" title="拉普拉斯Laplacian算子"></a>拉普拉斯Laplacian算子</h4><p>拉普拉斯算子模板的基本要求是对应的中心像素的系数应是正的，对应中心像素邻近像素的系数应是负的，且系数总和为0. </p><h4 id="马尔Marr算子"><a href="#马尔Marr算子" class="headerlink" title="马尔Marr算子"></a>马尔Marr算子</h4><p>由于拉普拉斯算子对噪声敏感，为了减少噪声的影响，可在检测前先对图像平滑处理，再用拉普拉斯算子。由于一个给定像素点所对应场景点的周围点对该点的光强贡献呈高斯分布，所以可使用高斯加权函数作为平滑函数。将高斯加权平滑运算与拉普拉斯运算结合即是马尔边缘检测方法。 </p><h4 id="Canny算子"><a href="#Canny算子" class="headerlink" title="Canny算子"></a>Canny算子</h4><ol><li>彩色图像转换为灰度图像</li><li>对图像进行高斯模糊</li><li>计算图像梯度，根据梯度计算图像边缘幅值与角度（这里其实用到了微分边缘检测算子来计算梯度幅值方向）</li><li>非最大信号压制处理（边缘细化）</li><li>双阈值边缘连接处理</li><li>二值化图像输出结果</li></ol><hr><h2 id="仿射变换"><a href="#仿射变换" class="headerlink" title="仿射变换"></a>仿射变换</h2><p> 仿射变换可以理解为<br>・对坐标进行放缩，旋转，平移后取得新坐标的值。<br>・经过对坐标轴的放缩，旋转，平移后原坐标在在新坐标领域中的值。</p><p>translate scale rotate shear reflect</p><hr><h2 id="直方图均衡化"><a href="#直方图均衡化" class="headerlink" title="直方图均衡化"></a>直方图均衡化</h2><ol><li>各个灰度级别的出现频率  即灰度直方图</li><li>各个灰度的累计分布</li><li>累计分布 进行量化 rq(i)=ROUND(r(i)*15)，（说明：量化公式中的15等于原始图像灰度级数减1）</li><li>按照量化后的对应关系，灰度值转换 即可</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;总结十个图像处理处理高频面试问题。&lt;br&gt;
    
    </summary>
    
      <category term="就业" scheme="https://ykksmile.top/categories/%E5%B0%B1%E4%B8%9A/"/>
    
    
      <category term="MachineLearning" scheme="https://ykksmile.top/tags/MachineLearning/"/>
    
      <category term="DeepLearning" scheme="https://ykksmile.top/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>十个深度学习高频面试问题</title>
    <link href="https://ykksmile.top/posts/60220/"/>
    <id>https://ykksmile.top/posts/60220/</id>
    <published>2018-10-16T06:55:46.000Z</published>
    <updated>2018-10-31T11:57:17.076Z</updated>
    
    <content type="html"><![CDATA[<p>总结十个深度学习高频面试问题。</p><a id="more"></a><hr><h2 id="一、过拟合-欠拟合"><a href="#一、过拟合-欠拟合" class="headerlink" title="一、过拟合/欠拟合"></a>一、过拟合/欠拟合</h2><h3 id="降低过拟合"><a href="#降低过拟合" class="headerlink" title="降低过拟合"></a>降低过拟合</h3><p>首先是数据角度，然后是特征角度，模型角度，分算法的角度。</p><ul><li>数据角度<ul><li>增加数据（GAN，图像增强，NLP机器翻译）</li><li>交叉验证k-fold</li><li>bootstrapping out of bag包外估计</li></ul></li><li>特征角度<ul><li>特征选择</li><li>降维</li></ul></li><li>模型角度<ul><li>正则化罚参数（看后面正则化）</li><li>更简单模型</li><li>减少迭代次数</li><li>集成学习（RF，GBDT） （<strong>关于GBDT XGboost后面</strong>）</li></ul></li><li>分算法的角度<ul><li>SVM  —— 引入松弛变量</li><li>决策树 —— 剪枝（预剪枝，后剪枝）</li><li>深度学习<ul><li>dropout bagging所有模型独立，训练到收敛，dropout共享参数，训练一小部分</li><li>batch normalization  BN归一化+训练每个batch得到方差+求均值方差的期望调整BN函数</li></ul></li><li>BP<ul><li>early stopping</li><li>regularization</li></ul></li></ul></li></ul><h3 id="降低欠拟合"><a href="#降低欠拟合" class="headerlink" title="降低欠拟合"></a>降低欠拟合</h3><p>从特征角度和模型角度（包括正则化）</p><ul><li>加入新的特征<ul><li>交叉组合特征（联想深度学习一般步骤）</li><li>深度学习： 因子分解，deep-crossing，自编码器</li></ul></li><li>增加模型复杂度<ul><li>线性：增加高次项</li><li>神经网络：增加层数和神经元</li></ul></li><li>减小正则化系数</li></ul><hr><h2 id="二、公式推导"><a href="#二、公式推导" class="headerlink" title="二、公式推导"></a>二、公式推导</h2><h3 id="BP反向传播的4个基本公式"><a href="#BP反向传播的4个基本公式" class="headerlink" title="BP反向传播的4个基本公式"></a>BP反向传播的4个基本公式</h3><p>利用链式法则求梯度下降法的梯度（每日一推）</p><hr><h2 id="三、激活函数"><a href="#三、激活函数" class="headerlink" title="三、激活函数"></a>三、激活函数</h2><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><ul><li>sigmoid</li><li>tanh</li><li>relu</li></ul><h3 id="为什么引入非线性激活函数"><a href="#为什么引入非线性激活函数" class="headerlink" title="为什么引入非线性激活函数"></a>为什么引入非线性激活函数</h3><p>深层神经网络不再是线性，可以逼近任何函数</p><h3 id="为什么relu"><a href="#为什么relu" class="headerlink" title="为什么relu"></a>为什么relu</h3><ul><li>sigmoid 梯度不好求</li><li>深层网络  sigmoid 梯度消失（见梯度爆炸和梯度消失）</li><li>relu使网络稀疏，缓解过拟合</li></ul><h3 id="relu的优缺点"><a href="#relu的优缺点" class="headerlink" title="relu的优缺点"></a>relu的优缺点</h3><ul><li>分段线性，梯度大（不会梯度消失）—，收敛快，使一部分神经元为0，使网络稀疏</li><li>某些神经元不会被激活</li></ul><h3 id="leaky-relu"><a href="#leaky-relu" class="headerlink" title="leaky-relu"></a>leaky-relu</h3><p>max(0,z)+a*min(0,z)   a为小值  a=-1为绝对值整流  a可学习为参数化整流</p><h3 id="其他激活函数"><a href="#其他激活函数" class="headerlink" title="其他激活函数"></a>其他激活函数</h3><ul><li>线性</li><li>softmax</li><li>径向基函数RBF</li><li>softplus</li><li>硬双曲正切</li></ul><hr><h2 id="四、正则化问题"><a href="#四、正则化问题" class="headerlink" title="四、正则化问题"></a>四、正则化问题</h2><p>正则化参数引入先验分布，降低复杂度，提高泛化能力</p><h3 id="BN是一种正则化方法，见上面（参数初始化）"><a href="#BN是一种正则化方法，见上面（参数初始化）" class="headerlink" title="BN是一种正则化方法，见上面（参数初始化）"></a>BN是一种正则化方法，见上面（参数初始化）</h3><h3 id="L1-L2-范数正则化"><a href="#L1-L2-范数正则化" class="headerlink" title="L1/L2 范数正则化"></a>L1/L2 范数正则化</h3><ul><li>L1 先验：拉普拉斯分布  使特征稀疏，便于提取</li><li>L2 先验：高斯分布  防止过拟合，提高泛化</li></ul><h3 id="dropout"><a href="#dropout" class="headerlink" title="dropout"></a>dropout</h3><p>集成方法bagging，多个数据集，重复采样</p><p>dropout，从基础网络去除部分单元后的子网络</p><hr><h2 id="五、正负样本不均衡"><a href="#五、正负样本不均衡" class="headerlink" title="五、正负样本不均衡"></a>五、正负样本不均衡</h2><ul><li>采样<ul><li>上采样 小众类多份</li><li>下采样 大众类剔除一部分</li><li>减少信息损失<ul><li>EasyEnsemble —— ensemble 模型融合 多次下采样</li><li>BalanceCascade —— boosting 增量训练 先训练下采样，正确的不放回，再训练第二个分类器</li><li>NearMiss —— KNN挑选大众样本</li></ul></li></ul></li><li>数据合成<ul><li>SMOTE方法 样本生成更多数据</li></ul></li><li>加权/罚函数</li><li>一分类或异常检测（高斯分布）</li></ul><hr><h2 id="六、梯度消失和梯度爆炸"><a href="#六、梯度消失和梯度爆炸" class="headerlink" title="六、梯度消失和梯度爆炸"></a>六、梯度消失和梯度爆炸</h2><h3 id="链式求导"><a href="#链式求导" class="headerlink" title="链式求导"></a>链式求导</h3><p>激活函数求导，大于一，导致梯度爆炸，小于一，梯度消失</p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ul><li>预训练加微调 DBN寻找局部最优（<strong>DBN</strong>）</li><li>梯度剪切 设置梯度的阈值 防止梯度爆炸</li><li>正则化 防止梯度爆炸</li><li>relu leakyrelu elu等激活函数</li><li>BN</li><li>残差结构</li><li>LSTM</li></ul><hr><h2 id="七、-CNN"><a href="#七、-CNN" class="headerlink" title="七、 CNN"></a>七、 CNN</h2><h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><ul><li>左<ul><li>去均值</li><li>归一化</li><li>PCA</li></ul></li><li>中<ul><li>CONV 卷积  局部感知，权值共享</li><li>RELU 激励 激活函数，收敛快，求梯度简单</li><li>POOL 池化  区域平均，降维</li></ul></li><li>右<ul><li>FC 全连接</li></ul></li></ul><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul><li>局部感知- 局部特征</li><li>权重共享 - 降低训练难度</li><li>池化 - 降维</li><li>多层次</li></ul><h3 id="感受野"><a href="#感受野" class="headerlink" title="感受野"></a>感受野</h3><p>感受野是卷积神经网络(CNN)每一层输出的特征图(feature map)上的像素点在原始输入图像上映射的区域大小</p><p>增大的方法： dilated空洞卷积，池化，增大卷积核</p><p> RF = 1 #待计算的feature map上的感受野大小<br>　　for layer in （top layer To down layer）:<br>　　　　RF = ((RF -1)* stride) + fsize<br>　　　　<br>后一层的fsize-1，乘上stride，然后加上当前层的fsize</p><h3 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><ul><li>时间复杂度</li></ul><p>M2K2CinCout<br>M 每个卷积核输出特征图的边长<br>K 每个卷积核的边长<br>Cin 输入通道数<br>Cout 输出通道数</p><ul><li>空间复杂度</li></ul><p>累加K2CinCout 与输入数据大小无关</p><hr><h2 id="八、-RNN-LSTM"><a href="#八、-RNN-LSTM" class="headerlink" title="八、 RNN LSTM"></a>八、 RNN LSTM</h2><hr><h2 id="九、-模型压缩和加速方法"><a href="#九、-模型压缩和加速方法" class="headerlink" title="九、 模型压缩和加速方法"></a>九、 模型压缩和加速方法</h2><p>分为四个类别，参数修剪和共享，低秩分解，迁移/压缩卷积滤波器，知识精炼</p><h3 id="参数修剪和共享"><a href="#参数修剪和共享" class="headerlink" title="参数修剪和共享"></a>参数修剪和共享</h3><h4 id="模型量化和二进制化"><a href="#模型量化和二进制化" class="headerlink" title="模型量化和二进制化"></a>模型量化和二进制化</h4><p>网络量化通过减少表示每个权重所需的比特数来压缩原始网络</p><p>缺陷：此类二元网络的准确率在处理大型 CNN 网络如 GoogleNet 时会大大降低。另一个缺陷是现有的二进制化方法都基于简单的矩阵近似，忽视了二进制化对准确率损失的影响。</p><h4 id="剪枝和共享"><a href="#剪枝和共享" class="headerlink" title="剪枝和共享"></a>剪枝和共享</h4><ul><li>偏差权重衰减</li><li>最优脑损伤</li><li>最有脑手术</li></ul><p>缺陷：剪枝和共享方法存在一些潜在的问题。首先，若使用了 L1 或 L2 正则化，则剪枝方法需要更多的迭代次数才能收敛，此外，所有的剪枝方法都需要手动设置层的敏感度，即需要精调超参数，在某些应用中会显得很冗长繁重。</p><h4 id="设计结构化矩阵"><a href="#设计结构化矩阵" class="headerlink" title="设计结构化矩阵"></a>设计结构化矩阵</h4><p>如果一个 m x n 阶矩阵只需要少于 m×n 个参数来描述，就是一个结构化矩阵（structured matrix）。通常这样的结构不仅能减少内存消耗，还能通过快速的矩阵-向量乘法和梯度计算显著加快推理和训练的速度。</p><h3 id="低秩分解和稀疏性"><a href="#低秩分解和稀疏性" class="headerlink" title="低秩分解和稀疏性"></a>低秩分解和稀疏性</h3><p>一个典型的 CNN 卷积核是一个 4D 张量，需要注意的是这些张量中可能存在大量的冗余。而基于张量分解的思想也许是减少冗余的很有潜力的方法。而全连接层也可以当成一个 2D 矩阵，低秩分解同样可行。</p><p>缺陷：低秩方法很适合模型压缩和加速，该方法补充了深度学习的近期发展，如 dropout、修正单元（rectified unit）和 maxout。但是，低秩方法的实现并不容易，因为它涉及计算成本高昂的分解操作。另一个问题是目前的方法逐层执行低秩近似，无法执行非常重要的全局参数压缩，因为不同的层具备不同的信息。最后，分解需要大量的重新训练来达到收敛。</p><h3 id="迁移-压缩卷积滤波器"><a href="#迁移-压缩卷积滤波器" class="headerlink" title="迁移/压缩卷积滤波器"></a>迁移/压缩卷积滤波器</h3><p>将变换矩阵应用到层或滤波器Φ(·) 来对整个网络模型进行压缩</p><p>缺陷：将迁移信息应用到卷积滤波器的方法需要解决几个问题。首先，这些方法的性能可与宽/平坦的架构（如 VGGNet）相媲美，但是无法与较窄/特殊的架构（如 GoogleNet、Residual Net）相比。其次，迁移假设有时过于强大以致于无法指导算法，使得在某些数据集上的结果不稳定。</p><h3 id="知识精炼"><a href="#知识精炼" class="headerlink" title="知识精炼"></a>知识精炼</h3><p>KD 压缩框架，即通过遵循学生-教师的范式减少深度网络的训练量，这种学生-教师的范式即通过软化教师的输出而惩罚学生。该框架将深层网络（教师）的集成压缩为相同深度的学生网络。</p><p>缺点：基于 KD 的方法能令更深的模型变得更加浅而显著地降低计算成本。但是也有一些缺点，例如 KD 方法只能用于具有 Softmax 损失函数分类任务，这阻碍了其应用。另一个缺点是模型的假设有时太严格了，以至于其性能有时比不上其它方法。</p><hr><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><h3 id="完整机器学习项目流程"><a href="#完整机器学习项目流程" class="headerlink" title="完整机器学习项目流程"></a>完整机器学习项目流程</h3><ol><li>抽象建模</li><li>获取数据</li><li>特征预处理</li><li>训练模型调优</li><li>模型诊断</li><li>模型融合</li><li>上线</li></ol><h3 id="线性与非线性"><a href="#线性与非线性" class="headerlink" title="线性与非线性"></a>线性与非线性</h3><ul><li>线性分类器解释性好，复杂度低  LR 贝叶斯 单层感知机 线性回归</li><li>非线性拟合能力强  决策树 RF GBDT 多层感知机</li><li>SVM 看线性核还是高斯核</li></ul><h3 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h3><p>优点： 提高梯度下降法的速度，有可能提高精度</p><ul><li>线性归一化</li><li>标准差归一化</li><li>非线性归一化</li></ul><p>caution: 概率模型不需要归一化，比如决策树，RF ； LR不用归一化 ； SVM 欧氏距离，要做归一化</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;总结十个深度学习高频面试问题。&lt;/p&gt;
    
    </summary>
    
      <category term="就业" scheme="https://ykksmile.top/categories/%E5%B0%B1%E4%B8%9A/"/>
    
    
      <category term="MachineLearning" scheme="https://ykksmile.top/tags/MachineLearning/"/>
    
      <category term="DeepLearning" scheme="https://ykksmile.top/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>做过的几个项目总结</title>
    <link href="https://ykksmile.top/posts/59325/"/>
    <id>https://ykksmile.top/posts/59325/</id>
    <published>2018-10-16T05:17:24.000Z</published>
    <updated>2018-10-16T07:04:20.941Z</updated>
    
    <content type="html"><![CDATA[<p>总结一下做过的几个项目，包括蜂窝链路聚合、遮挡人脸识别、车牌识别、交通流量预测等等。</p><a id="more"></a><hr><h2 id="非机器学习相关"><a href="#非机器学习相关" class="headerlink" title="非机器学习相关"></a>非机器学习相关</h2><h3 id="民用客机维护与信息服务一体化机载系统技术研究"><a href="#民用客机维护与信息服务一体化机载系统技术研究" class="headerlink" title="民用客机维护与信息服务一体化机载系统技术研究"></a>民用客机维护与信息服务一体化机载系统技术研究</h3><p>与中航工业631所合作的国家自然基金项目，选用IPsec、SIM模块、多网卡PC，设计并实现应用于民航客机的加密蜂窝链路聚合链路，并使用C语言开发WCMS无线通信管理软件的主程序、路由模块、AT模块等大部分代码（开发环境ubuntu）。</p><p>使用：SIM7100 天融信IPsec 多网卡PC</p><p>核心： C语言实现多线程，iptables实现路由，C语言实现AT模块串口通信、IPsec加密链路</p><h3 id="基于SDN-NFV思想的天地一体化组网技术"><a href="#基于SDN-NFV思想的天地一体化组网技术" class="headerlink" title="基于SDN/NFV思想的天地一体化组网技术"></a>基于SDN/NFV思想的天地一体化组网技术</h3><p>与北京电科院合作的国家863计划，使用Floodlight控制器，搭建基于SDN的异构组网演示环境，通过下发流表（Python）对异构天地通信网络实现控制。</p><p>使用：floodlight控制器</p><p>核心：SDN，Python下发流表（通过http协议，actions，同时使用RPC远程控制协议）</p><h3 id="车联网车路协同信息服务技术"><a href="#车联网车路协同信息服务技术" class="headerlink" title="车联网车路协同信息服务技术"></a>车联网车路协同信息服务技术</h3><p>基于DSP+雷达模块完成雷达信号采集的硬件系统设计，深入研究毫米波雷达的前端数字信号处理方法和后端目标检测识别算法；基于opencv和nanopi搭建ARM环境下的视频车辆检测系统。</p><p>技术： 使用sin和cos模拟雷达输入分IQ数据，加入直流分量模拟，多目标识别。</p><p>使用：TMS320F28335 前端放大器，傅里叶变换，采样定理，滤波，多普勒定理获得速度；目标识别使用nanopi上的opencv，车辆cascade模型</p><hr><h2 id="机器学习相关"><a href="#机器学习相关" class="headerlink" title="机器学习相关"></a>机器学习相关</h2><h3 id="基于深度学习的特殊车牌识别"><a href="#基于深度学习的特殊车牌识别" class="headerlink" title="基于深度学习的特殊车牌识别"></a>基于深度学习的特殊车牌识别</h3><p>基于开源Hyperlpr，使用程序生成特殊车牌（军用警用香港澳门双层等），分别使用级联CNN和级联GRU训练E2E的神经网络并用于车牌识别，参加研究生智慧城市大赛取得TOP14。</p><p>核心： CNN,GRU,keras  形态学，边缘检测，车牌定位，车牌识别（OCR,GRU）  生成exe程序（py2exe），pyqt写界面</p><h3 id="遮挡人脸识别"><a href="#遮挡人脸识别" class="headerlink" title="遮挡人脸识别"></a>遮挡人脸识别</h3><p>广泛阅读论文，opencv，mtcnn，RPCA（鲁棒PCA ，稀疏解）</p><h3 id="交通流量预测"><a href="#交通流量预测" class="headerlink" title="交通流量预测"></a>交通流量预测</h3><p>LSTM+SVR</p><h3 id="Spooky-Author-Identification"><a href="#Spooky-Author-Identification" class="headerlink" title="Spooky Author Identification"></a>Spooky Author Identification</h3><p>xgboost</p><h3 id="华为软件精英挑战赛"><a href="#华为软件精英挑战赛" class="headerlink" title="华为软件精英挑战赛"></a>华为软件精英挑战赛</h3><p>手工实现LSTM,SVR,LR,RF,指数平滑等，做销量预测。</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;总结一下做过的几个项目，包括蜂窝链路聚合、遮挡人脸识别、车牌识别、交通流量预测等等。&lt;/p&gt;
    
    </summary>
    
      <category term="Notes" scheme="https://ykksmile.top/categories/Notes/"/>
    
      <category term="科研" scheme="https://ykksmile.top/categories/Notes/%E7%A7%91%E7%A0%94/"/>
    
    
      <category term="MachineLearning" scheme="https://ykksmile.top/tags/MachineLearning/"/>
    
      <category term="DeepLearning" scheme="https://ykksmile.top/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>交通流量预测工作时间轴</title>
    <link href="https://ykksmile.top/posts/49229/"/>
    <id>https://ykksmile.top/posts/49229/</id>
    <published>2018-07-04T02:06:54.000Z</published>
    <updated>2018-07-04T07:20:42.359Z</updated>
    
    <content type="html"><![CDATA[<p>主要工作时间轴，包括论文的阅读整理、实验方案的确定、数据的预处理和训练。因为涉及到毕业设计，在这里只讲方法不讲内容。</p><a id="more"></a><hr><h2 id="论文阅读整理"><a href="#论文阅读整理" class="headerlink" title="论文阅读整理"></a>论文阅读整理</h2><h3 id="1-基于深度学习的短时交通流预测"><a href="#1-基于深度学习的短时交通流预测" class="headerlink" title="1-基于深度学习的短时交通流预测"></a>1-基于深度学习的短时交通流预测</h3><h4 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h4><p>差分处理（说的高大上）</p><h4 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h4><p>使用DBN，深度信念网络，由多个限制玻尔兹曼机（RBM）叠加，顶层加一个SVR来预测流量。</p><ul><li>DBN 特征学习</li><li>特征H丢进SVR预测</li><li>反差分</li></ul><h4 id="误差分析"><a href="#误差分析" class="headerlink" title="误差分析"></a>误差分析</h4><p>均方误差MSE<br>平均百分比误差MAPE</p><h4 id="模型对比"><a href="#模型对比" class="headerlink" title="模型对比"></a>模型对比</h4><p>与浅层的NN和SVR</p><h3 id="2-大规模交通流预测方法研究"><a href="#2-大规模交通流预测方法研究" class="headerlink" title="2-大规模交通流预测方法研究"></a>2-大规模交通流预测方法研究</h3><h4 id="预处理-1"><a href="#预处理-1" class="headerlink" title="预处理"></a>预处理</h4><p>进行抽样，抽样率。</p><p>kmeans聚类，每类进行抽样。</p><h4 id="模型结构-1"><a href="#模型结构-1" class="headerlink" title="模型结构"></a>模型结构</h4><p>SMO的SVR</p><h4 id="误差分析-1"><a href="#误差分析-1" class="headerlink" title="误差分析"></a>误差分析</h4><p>MSE MAE MAPE 训练时间</p><h4 id="模型对比-1"><a href="#模型对比-1" class="headerlink" title="模型对比"></a>模型对比</h4><p>无</p><h3 id="3-基于CNN-SVR混合深度学习模型的短时交通流预测"><a href="#3-基于CNN-SVR混合深度学习模型的短时交通流预测" class="headerlink" title="3-基于CNN_SVR混合深度学习模型的短时交通流预测"></a>3-基于CNN_SVR混合深度学习模型的短时交通流预测</h3><h4 id="预处理-2"><a href="#预处理-2" class="headerlink" title="预处理"></a>预处理</h4><p>没处理</p><h4 id="模型结构-2"><a href="#模型结构-2" class="headerlink" title="模型结构"></a>模型结构</h4><p>单隐层CNN+SVR  Adam替代SGD</p><h4 id="误差分析-2"><a href="#误差分析-2" class="headerlink" title="误差分析"></a>误差分析</h4><p>MAE RMSE</p><h4 id="模型对比-2"><a href="#模型对比-2" class="headerlink" title="模型对比"></a>模型对比</h4><p>与单独的CNN和SVR对比  残差对比</p><h4 id="4-基于车联网的短时交通流预测算法研究"><a href="#4-基于车联网的短时交通流预测算法研究" class="headerlink" title="4-基于车联网的短时交通流预测算法研究"></a>4-基于车联网的短时交通流预测算法研究</h4><p><img src="https://blog-1252404748.cos.ap-chengdu.myqcloud.com/images/jiaotongliuyuce.png" alt="交通流量预测模型"></p><h4 id="预处理-3"><a href="#预处理-3" class="headerlink" title="预处理"></a>预处理</h4><p> <a href="http://www.dot.ca.gov/trafficops/mpr/source.html" target="_blank" rel="noopener">pems数据集</a><br>剔除无效数据 插值补全<br>30s数据进行聚合<br>获得speed flow occupancy三种数据源</p><h4 id="模型结构-3"><a href="#模型结构-3" class="headerlink" title="模型结构"></a>模型结构</h4><p>基于卡尔曼滤波<br>基于相空间重构的卡尔曼滤波<br>小波神经网络WNN 基于时空特性</p><h4 id="误差分析-3"><a href="#误差分析-3" class="headerlink" title="误差分析"></a>误差分析</h4><p>MAE 平均相对误差MRE 均方根误差RMSE 均方百分比误差MSPE 均等系数EC</p><h4 id="模型对比-3"><a href="#模型对比-3" class="headerlink" title="模型对比"></a>模型对比</h4><p>工作日 非工作日</p><h3 id="5-基于深度学习的短时交通流预测研究（√）"><a href="#5-基于深度学习的短时交通流预测研究（√）" class="headerlink" title="5-基于深度学习的短时交通流预测研究（√）"></a>5-基于深度学习的短时交通流预测研究（√）</h3><h4 id="预处理-4"><a href="#预处理-4" class="headerlink" title="预处理"></a>预处理</h4><p>【深圳市南山大道数据集】<br>取下游路段t时刻及之前共m + 1个时刻的状态，和自身路段t时刻及之前n + 1个交通流状态共同构成的输入状态.<br>平稳化：一阶差分</p><h4 id="模型结构-4"><a href="#模型结构-4" class="headerlink" title="模型结构"></a>模型结构</h4><p>LSTM-RNN联合</p><h4 id="误差分析-4"><a href="#误差分析-4" class="headerlink" title="误差分析"></a>误差分析</h4><p>MAE 平均相对误差MRE 均方根误差RMSE 均方百分比误差MSPE 均等系数EC<br>不同深度和结构的模型的误差水平<br>训练时间</p><blockquote><p>DropOut层设定随机断开 20%的神经元，Dense为全连接层.优化器为“Nadam”，激活函数为“tanh”，损失函数为MSE.实验发现，随着 Epoch 的增加，训练时长增加，模型的训练误差会随之降低，但是 Epoch增大到一定程度，则可能出现过拟合现象.对于比较小的数据集，Batchsize可以采用全数据集的形式，因为全数据集确定的方向能够更好的代表样本总体，从而更准确地朝向极值所在的方向下降.相反的，Batchsize 等于 1 时(在线学习模式)，每次修正的梯度方向都会发生变化，有可能横冲直撞，难以收敛.因此，这 2 个参数的选择应该首先针对样本集的大小确定一个大致的范围，再经过仔细调节，寻找到合适的值，达到兼顾精度和时效性的要求</p></blockquote><h4 id="模型对比-4"><a href="#模型对比-4" class="headerlink" title="模型对比"></a>模型对比</h4><p>BPNN RNN</p><h3 id="6-基于深度学习的短时交通拥堵预测模型"><a href="#6-基于深度学习的短时交通拥堵预测模型" class="headerlink" title="6-基于深度学习的短时交通拥堵预测模型"></a>6-基于深度学习的短时交通拥堵预测模型</h3><h4 id="预处理-5"><a href="#预处理-5" class="headerlink" title="预处理"></a>预处理</h4><p>【北京浮动车辆 GPS 数据】</p><ul><li>剔除无效数据</li><li>筛选有意义数据</li><li>路段匹配</li></ul><h4 id="模型结构-5"><a href="#模型结构-5" class="headerlink" title="模型结构"></a>模型结构</h4><p>基于SAE（堆叠自动编码器）</p><h4 id="误差分析-5"><a href="#误差分析-5" class="headerlink" title="误差分析"></a>误差分析</h4><p>MSE RMSE</p><h4 id="模型对比-5"><a href="#模型对比-5" class="headerlink" title="模型对比"></a>模型对比</h4><p>比较 SAE 模型、 SVR 模型、 BP 神经网络、 RNN 神经网络以及 LSTM神经网络来分析平均速度预测模型的性能</p><hr><h2 id="实验方案"><a href="#实验方案" class="headerlink" title="实验方案"></a>实验方案</h2><p>### </p><hr><h2 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h2><p>### </p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;主要工作时间轴，包括论文的阅读整理、实验方案的确定、数据的预处理和训练。因为涉及到毕业设计，在这里只讲方法不讲内容。&lt;/p&gt;
    
    </summary>
    
      <category term="Notes" scheme="https://ykksmile.top/categories/Notes/"/>
    
      <category term="科研" scheme="https://ykksmile.top/categories/Notes/%E7%A7%91%E7%A0%94/"/>
    
    
      <category term="MachineLearning" scheme="https://ykksmile.top/tags/MachineLearning/"/>
    
      <category term="DeepLearning" scheme="https://ykksmile.top/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>深信服长沙之旅</title>
    <link href="https://ykksmile.top/posts/63136/"/>
    <id>https://ykksmile.top/posts/63136/</id>
    <published>2018-07-03T13:50:03.000Z</published>
    <updated>2018-07-24T09:00:13.197Z</updated>
    
    <content type="html"><![CDATA[<p>7.10号到7.14号前往长沙参加了深信服网络技术挑战赛，决赛分为设备配置和方案设计两部分，最终取得了优秀个人和团队亚军，十分可惜。</p><a id="more"></a><hr><h2 id="设备配置"><a href="#设备配置" class="headerlink" title="设备配置"></a>设备配置</h2><h3 id="IPsec-VPN互联"><a href="#IPsec-VPN互联" class="headerlink" title="IPsec VPN互联"></a>IPsec VPN互联</h3><p>客户的此环境有 NAT 环境 ，双方有固定的公网 IP，此环境下，选择野蛮模式进行<br>对接。 注：不能用主模式。</p><p>两端配置，实现长沙 WOC 和深圳 SSL VPN 设备上的 IPsec VPN 的第一、二阶段的协商。</p><p>标准 IPSEC VPN 采用 UDP 500 端口进行 IKE 参数协商等过程，在 NAT 环境中用<br>UDP4500 端口进行协商并提供服务。</p><p>由于长沙 WOC 和深圳 SSL VPN设备都使用内网地址，不能在公网路由。因此要实现上网需求，需要在长沙 AC 设备和深圳 AD 设备上配置源地址转换（NAT代理上网）。</p><p>注意事项：</p><ul><li>两端配IKE协商（感兴趣流）</li><li>在AC和AD上配置NAT</li><li>在深圳总部出口 AD 上做 UDP 500 和 4500端口映射（DNAT）</li><li>添加静态路由</li></ul><p>思考：</p><ol><li>标准 IPSEC VPN 中出、入站（感兴趣流）的作用是什么？<br>用来触发 IPSEC VPN， 用来分辨哪些流量走IPsec</li><li>两端都是拨号的场景能否建立标准 IPSEC VPN，如果可以，如何操作？<br>SSL 出口是拨号上网获取的动态 IP，可以申请 webagent，外网用户通过 webagent 地址<br>访问 SSL VPN，SSL VPN 上设置 webagent 地址会定时发送 SSL VPN 实时地址给<br>webagent。</li></ol><h3 id="SANGFOR-VPN-互联"><a href="#SANGFOR-VPN-互联" class="headerlink" title="SANGFOR VPN 互联"></a>SANGFOR VPN 互联</h3><ul><li>作为总部，只需要创建分支用户，让分支可以使用该用户访问总部，不需要设置 VPN 连接。</li><li>发布深圳总部的其他网段</li><li>SANGFOR VPN 协议端口是 4009 端口映射（UDP TCP）</li><li>在长沙分支的 WOC 设备中【Sangfor VPN】－【客户端】－【连接管理】中，点击【新增】</li><li>长沙分支NAT</li><li>配置路由</li></ul><ol><li>分支出口设备是否需要做端口映射 SANGFOR VPN 的端口？<br>不需要，只需要在长沙分支 AC 上做 NAT 代理上网就可以。</li></ol><h3 id="SANGFOR-PDLAN-互联"><a href="#SANGFOR-PDLAN-互联" class="headerlink" title="SANGFOR PDLAN 互联"></a>SANGFOR PDLAN 互联</h3><ul><li>深圳总部 SSLVPN 设备配置 sangfor VPN，配置 webagent 地址，创建账号及账号的策略</li><li>新增并建立虚拟IP （考虑回包路由）</li><li>4009的UDP TCP 端口映射</li><li>PDLAN 配 置（客户端） 配置用户和 webagent </li><li>总部序列号配置中的授权是否足够</li></ul><ol><li>虚拟 IP 池里面的 IP 可以随意设置吗？<br>可以，但是一定要考虑回包路由的问题。</li><li>PC 登陆 PDLAN 之后，数据是如何进入隧道的？<br>通过虚拟 IP 进入隧道，虚拟网卡对数据进行重新加密封装，将数据送入 VPN 隧道。</li></ol><hr><h2 id="方案设计"><a href="#方案设计" class="headerlink" title="方案设计"></a>方案设计</h2><p>### </p><hr><h2 id="收获和反思"><a href="#收获和反思" class="headerlink" title="收获和反思"></a>收获和反思</h2><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;7.10号到7.14号前往长沙参加了深信服网络技术挑战赛，决赛分为设备配置和方案设计两部分，最终取得了优秀个人和团队亚军，十分可惜。&lt;/p&gt;
    
    </summary>
    
      <category term="Essays" scheme="https://ykksmile.top/categories/Essays/"/>
    
      <category term="学业" scheme="https://ykksmile.top/categories/Essays/%E5%AD%A6%E4%B8%9A/"/>
    
    
      <category term="ComputerNetwork" scheme="https://ykksmile.top/tags/ComputerNetwork/"/>
    
  </entry>
  
  <entry>
    <title>数据库和操作系统笔试题总结（针对19校招</title>
    <link href="https://ykksmile.top/posts/23140/"/>
    <id>https://ykksmile.top/posts/23140/</id>
    <published>2018-06-26T11:38:17.000Z</published>
    <updated>2018-07-24T09:00:09.086Z</updated>
    
    <content type="html"><![CDATA[<p>总结19年校招遇到的数据库和操作系统笔试面试题，分门别类，放好备用。</p><a id="more"></a><hr><h2 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h2><h3 id="题目总结"><a href="#题目总结" class="headerlink" title="题目总结"></a>题目总结</h3><ol><li><p>数据库中存在学生表S、课程表C和学生选课表SC三个表，它们的结构如下：S(S#，SN，SEX，AGE，DEPT)C(C#，CN)SC(S#，C#，GRADE)其中：S#为学号，SN为姓名，SEX为性别，AGE为年龄，DEPT为系别，C#为课程号，CN为课程名，GRADE为成绩。请检索选修课程号为C2的学生中成绩最高的学号。( )</p><p> SELECT S# FORM SC WHERE C#=“C2” AND GRADE＞＝ALL (SELECT GRADE FORM SC WHERE C#=“C</p></li><li><p>数据库保护主要包括<strong>__</strong>、<strong>__</strong>、<strong>__</strong>和<strong>__</strong>。</p><p> 数据的安全性、完整性、并发控制、数据库恢复等 </p></li><li><p>数据库中事务的四大特性（ACID）</p><p> 原子性 一致性 隔离性 持久性</p></li><li><p>什么是分布式数据库？<br> 具体来说，集群文件系统是指运行在多台计算机之上，之间通过某种方式相互通信从而将集群内所有存储空间资源整合、虚拟化并对外提供文件访问服务的文件系统。<br> HDFS 并行访问</p></li></ol><hr><h2 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h2><h3 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h3><p><strong>死锁产生的必要条件</strong>：</p><ul><li><p>互斥条件：进程要求对所分配的资源进行排他性控制，即在一段时间内某资源仅为一个进程所占用。此时若有其他进程请求该资源，则请求进程只能等待。</p></li><li><p>不剥夺条件：进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能由获得该资源的进程自己来释放。</p></li><li><p>请求和保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。</p></li><li><p>循环等待条件：存在一种进程资源的循环等待链，连中每一个进程已获得的资源同时被链中下一个进程所请求。</p></li></ul><p><strong>死锁避免</strong>：</p><ol><li>预防死锁(摒弃除1以外的条件)</li><li>避免死锁(银行家算法)</li><li>检测死锁(资源分配图)</li><li>解除死锁<ul><li>剥夺资源</li><li>撤销进程</li></ul></li></ol><h3 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h3><p>引入线程是为了减少程序在并发执行时所付出的时空开销。</p><p>定义：</p><p>一、进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动，是系统进行资源分配和调度的一个独立单位。<br>二、线程是进程的一个实体，是CPU调度和分派的基本单位，他是比进程更小的能独立运行的基本单位，线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源（如程序计数器，一组寄存器和栈），一个线程可以创建和撤销另一个线程；</p><p>进程和线程的关系：</p><p>（1）一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。<br>（2）资源分配给进程，同一进程的所有线程共享该进程的所有资源。<br>（3）线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步。<br>（4）处理机分给线程，即真正在处理机上运行的是线程。<br>（5）线程是指进程内的一个执行单元，也是进程内的可调度实体。<br>线程与进程的区别：<br>（1）调度：线程作为调度和分配的基本单位，进程作为拥有资源的基本单位。<br>（2）并发性：不仅进程之间可以并发执行，同一个进程的多个线程之间也可以并发执行。<br>（3）拥有资源：进程是拥有资源的一个独立单位，线程不拥有系统资源，但可以访问隶属于进程的资源。<br>（4）系统开销：在创建或撤销进程的时候，由于系统都要为之分配和回收资源，导致系统的明显大于创建或撤销线程时的开销。但进程有独立的地址空间，进程崩溃后，在保护模式下不会对其他的进程产生影响，而线程只是一个进程中的不同的执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但是在进程切换时，耗费的资源较大，效率要差些。</p><p>线程的划分尺度小于进程，使得多线程程序的并发性高。</p><p>另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大的提高了程序运行效率。</p><p>线程在执行过程中，每个独立的线程有一个程序运行的入口，顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，有应用程序提供多个线程执行控制。</p><p>从逻辑角度看，多线程的意义子啊与一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。这就是进程和线程的重要区别。</p><p><img src="https://blog-1252404748.cos.ap-chengdu.myqcloud.com/images/%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B.png" alt="进程线程"></p><hr><p>### </p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;总结19年校招遇到的数据库和操作系统笔试面试题，分门别类，放好备用。&lt;/p&gt;
    
    </summary>
    
      <category term="就业" scheme="https://ykksmile.top/categories/%E5%B0%B1%E4%B8%9A/"/>
    
      <category term="DataBase" scheme="https://ykksmile.top/categories/%E5%B0%B1%E4%B8%9A/DataBase/"/>
    
    
      <category term="DataBase" scheme="https://ykksmile.top/tags/DataBase/"/>
    
  </entry>
  
  <entry>
    <title>leetcode中Hashtable思路总结</title>
    <link href="https://ykksmile.top/posts/5454/"/>
    <id>https://ykksmile.top/posts/5454/</id>
    <published>2018-06-26T11:18:49.000Z</published>
    <updated>2018-06-26T11:56:50.128Z</updated>
    
    <content type="html"><![CDATA[<p>暂时没什么前言。</p><a id="more"></a><hr><h3 id="Happy-Number"><a href="#Happy-Number" class="headerlink" title="Happy Number"></a>Happy Number</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Time:  O(k), where k is the steps to be happy number</span></span><br><span class="line"><span class="comment"># Space: O(k)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Write an algorithm to determine if a number is "happy".</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># A happy number is a number defined by the following process: </span></span><br><span class="line"><span class="comment"># Starting with any positive integer, replace the number by the sum </span></span><br><span class="line"><span class="comment"># of the squares of its digits, and repeat the process until </span></span><br><span class="line"><span class="comment"># the number equals 1 (where it will stay), or it loops endlessly </span></span><br><span class="line"><span class="comment"># in a cycle which does not include 1. Those numbers for which </span></span><br><span class="line"><span class="comment"># this process ends in 1 are happy numbers.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Example: 19 is a happy number</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># 1^2 + 9^2 = 82</span></span><br><span class="line"><span class="comment"># 8^2 + 2^2 = 68</span></span><br><span class="line"><span class="comment"># 6^2 + 8^2 = 100</span></span><br><span class="line"><span class="comment"># 1^2 + 0^2 + 0^2 = 1</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># @param &#123;integer&#125; n</span></span><br><span class="line">    <span class="comment"># @return &#123;boolean&#125;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isHappy</span><span class="params">(self, n)</span>:</span></span><br><span class="line">        lookup = &#123;&#125;</span><br><span class="line">        <span class="keyword">while</span> n != <span class="number">1</span> <span class="keyword">and</span> n <span class="keyword">not</span> <span class="keyword">in</span> lookup:</span><br><span class="line">            lookup[n] = <span class="keyword">True</span></span><br><span class="line">            n = self.nextNumber(n)</span><br><span class="line">        <span class="keyword">return</span> n == <span class="number">1</span> <span class="comment"># True</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">nextNumber</span><span class="params">(self, n)</span>:</span></span><br><span class="line">        new = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> char <span class="keyword">in</span> str(n):</span><br><span class="line">            new += int(char)**<span class="number">2</span></span><br><span class="line"><span class="keyword">return</span> new</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span></span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isHappy</span><span class="params">(<span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">Set&lt;Integer&gt; set = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line"><span class="keyword">while</span>(n!=<span class="number">1</span>)&#123;</span><br><span class="line"><span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span>(n!=<span class="number">0</span>)&#123;</span><br><span class="line">sum += Math.pow((n%<span class="number">10</span>),<span class="number">2</span>);</span><br><span class="line">n/=<span class="number">10</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(set.contains(sum))&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">set.add(sum);</span><br><span class="line">n=sum;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p>### </p><hr><p>### </p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;暂时没什么前言。&lt;/p&gt;
    
    </summary>
    
      <category term="就业" scheme="https://ykksmile.top/categories/%E5%B0%B1%E4%B8%9A/"/>
    
      <category term="DataStructure" scheme="https://ykksmile.top/categories/%E5%B0%B1%E4%B8%9A/DataStructure/"/>
    
    
      <category term="Python" scheme="https://ykksmile.top/tags/Python/"/>
    
      <category term="Java" scheme="https://ykksmile.top/tags/Java/"/>
    
      <category term="Leetcode" scheme="https://ykksmile.top/tags/Leetcode/"/>
    
  </entry>
  
  <entry>
    <title>数据结构笔试题总结（针对19校招</title>
    <link href="https://ykksmile.top/posts/44954/"/>
    <id>https://ykksmile.top/posts/44954/</id>
    <published>2018-06-26T10:40:39.000Z</published>
    <updated>2018-10-31T11:57:47.559Z</updated>
    
    <content type="html"><![CDATA[<p>总结19年校招遇到的数据结构笔试面试题，分门别类，放好备用。</p><a id="more"></a><hr><h3 id="赫夫曼树"><a href="#赫夫曼树" class="headerlink" title="赫夫曼树"></a>赫夫曼树</h3><p><a href="https://blog.csdn.net/wtfmonking/article/details/17150499" target="_blank" rel="noopener">哈夫曼树 C语言实现</a></p><p><strong>路径长度</strong>：<br>从树中一个结点到另一个结点之间的分支构成两个节点的路径，路径上的分支数目称作路径长度。</p><p><strong>WPL带权路径长度</strong>：<br>路径长度与节点上权的乘积。</p><p><code>WPL最短的树叫做赫夫曼树。</code></p><p><strong>赫夫曼编码</strong>：</p><p>字符集d1 d2 d3… 频率w1 w2 w3…</p><p>d为结点 w为权值构造赫夫曼树 左分支代表0 右分支代表1 根节点到叶子结点所经过的0和1的序列，即为赫夫曼编码。</p><p><strong>构造规则</strong>：</p><p>假设有n个权值，则构造出的哈夫曼树有n个叶子结点。 n个权值分别设为 w1、w2、…、wn，则哈夫曼树的构造规则为：</p><p>(1) 将w1、w2、…，wn看成是有n 棵树的森林(每棵树仅有一个结点)；</p><p>(2) 在森林中选出两个根结点的权值最小的树合并，作为一棵新树的左、右子树，且新树的根结点权值为其左、右子树根结点权值之和；</p><p>(3)从森林中删除选取的两棵树，并将新树加入森林；</p><p>(4)重复(2)、(3)步，直到森林中只剩一棵树为止，该树即为所求得的哈夫曼树。</p><hr><h3 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h3><ol><li>设数组定义为a[60][70]，每个元素占2个存储单元，数组按照<code>列优先存储</code>，元素a[0][0]的地址为1024，那么元素a[32][58]的地址为（8048）</li></ol><p>a[60][70]有60行、70列，a[32][58]位于整个数组的33行、59列处，因为数组按照列优先存储，所以a[32][58]前面一共有</p><p>(59-1)<em>60+(33-1)=58</em>60+32=3512个元素，每个元素占2个存储单元，则一共占3512*2=7024个存储单元，</p><p>又因为a[32][58]的地址在2个存储单元的最前端，所以其地址为1024+7024=8048</p><hr><h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><ol><li>设有序表中有1000个元素,则用二分查找查找元素X最多需要比较【 】次.</li></ol><p>比较10次。<br>1个元素的时候比较1次<br>2~3个元素比较2次<br>4~7个元素比较3次<br>8~15                4<br>16~31              5<br>32~63              6<br>64~127            7<br>128~255          8<br>256~511          9<br>512~1023       10<br>就是log2n取整后 +1</p><ol><li>220下列排序算法中不能保证每趟排序至少能将一个元素放到其最终的位置上的是( )。</li></ol><p>A．快速排序<br>B．希尔排序<br>C．堆排序<br>D．起泡排序</p><p>B</p><ol><li>对大量数据排序(100万个),多种排序方法中,哪种最快、效率最高</li></ol><p>快速排序&gt;堆排序&gt;归并排序&gt;插入排序  数据达到10000000 堆排序优于快速排序</p><p><a href="https://blog.csdn.net/wqf363/article/details/1604458" target="_blank" rel="noopener">各种排序查询的算法效率比较</a></p><hr><h3 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h3><ol><li>已知一棵二叉树，如果先序遍历的节点顺序是：ADCEFGHB，中序遍历是：CDFEGHAB，则后序遍历结果为：（） </li></ol><p>CFHGEDBA</p><p>先序遍历简单记为：根左右<br>中序遍历简单记为：左根右<br>后序遍历简单记为：左右根 </p><ol start="2"><li>红黑树的性质</li></ol><p>map的底层实现</p><p>红黑树，作为一棵二叉查找树，满足二叉查找树的一般性质。下面，来了解下 二叉查找树的一般性质。<br>二叉查找树，也称有序二叉树（ordered binary tree），或已排序二叉树（sorted binary tree），是指一棵空树或者具有下列性质的二叉树：<br>若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值；<br>若任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值；<br>任意节点的左、右子树也分别为二叉查找树。<br>没有键值相等的节点（no duplicate nodes）。<br>因为一棵由n个结点随机构造的二叉查找树的高度为lgn，所以顺理成章，二叉查找树的一般操作的执行时间为O(lgn)。但二叉查找树若退化成了一棵具有n个结点的线性链后，则这些操作最坏情况运行时间为O(n)。<br>红黑树虽然本质上是一棵二叉查找树，但它在二叉查找树的基础上增加了着色和相关的性质使得红黑树相对平衡，从而保证了红黑树的查找、插入、删除的时间复杂度最坏为O(log n)。<br>但它是如何保证一棵n个结点的红黑树的高度始终保持在logn的呢？这就引出了红黑树的5个性质：</p><ul><li>每个结点要么是红的要么是黑的。  </li><li>根结点是黑的。  </li><li>每个叶结点（叶结点即指树尾端NIL指针或NULL结点）都是黑的。  </li><li>如果一个结点是红的，那么它的两个儿子都是黑的。  </li><li>对于任意结点而言，其到叶结点树尾端NIL指针的每条路径都包含相同数目的黑结点。</li></ul><p>正是红黑树的这5条性质，使一棵n个结点的红黑树始终保持了logn的高度，从而也就解释了上面所说的“红黑树的查找、插入、删除的时间复杂度最坏为O(log n)”这一结论成立的原因。</p><hr><h3 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h3><ol><li>若某表最常用的操作是在最后一个结点之后插入一个结点或删除最后一个结点。则采用（ ）存储方式最节省运算时间。</li></ol><p>双循环链表能够通过头结点的前驱就是尾结点，能够迅速找到尾结点，然后进行插入和删除操作</p><ol><li>已知一个线性表（38，25，74，63，52，48），假定采用散列函数h(key)=key%7计算散列地址，并散列存储在散列表A[0..6]中，若采用线性探测方法解决冲突，则在该散列表上进行等概率成功查找的平均查找长度为<strong>_</strong></li></ol><p>如果一个元素存入时，进行了N次散列，相应的查找次数也是N，所以38，25，63这三个元素的查找长度为1，74的查找长度为2，48的查找长度为3，52的查找长度为4。所以平均查找长度为：(1+1+1+2+3+4)/6=2。 </p><hr><h3 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h3><ol><li>哈希冲突。解决办法</li></ol><p>1）开放定址法：当冲突发生时，使用某种探查(亦称探测)技术在散列表中形成一个探查(测)序列。沿此序列逐个单元地查找，直到找到给定 的关键字，或者碰到一个开放的地址(即该地址单元为空)为止（若要插入，在探查到开放的地址，则可将待插入的新结点存人该地址单元）。查找时探查到开放的 地址则表明表中无待查的关键字，即查找失败。<br>2） 再哈希法：同时构造多个不同的哈希函数。<br>3）链地址法：将所有哈希地址为i的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第i个单元中，因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况。<br>4）建立公共溢出区：将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;总结19年校招遇到的数据结构笔试面试题，分门别类，放好备用。&lt;/p&gt;
    
    </summary>
    
      <category term="就业" scheme="https://ykksmile.top/categories/%E5%B0%B1%E4%B8%9A/"/>
    
      <category term="DataStructure" scheme="https://ykksmile.top/categories/%E5%B0%B1%E4%B8%9A/DataStructure/"/>
    
    
      <category term="DataStructure" scheme="https://ykksmile.top/tags/DataStructure/"/>
    
  </entry>
  
  <entry>
    <title>深信服复赛准备知识点</title>
    <link href="https://ykksmile.top/posts/42224/"/>
    <id>https://ykksmile.top/posts/42224/</id>
    <published>2018-06-21T12:51:00.000Z</published>
    <updated>2018-07-01T06:23:33.375Z</updated>
    
    <content type="html"><![CDATA[<p>准备深信服复赛。主要侧重安全部分（深信服是一家做安全的公司啊）。</p><a id="more"></a><hr><h2 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h2><h3 id="脆弱性"><a href="#脆弱性" class="headerlink" title="脆弱性"></a>脆弱性</h3><ul><li>缺乏数据源验证</li><li>缺乏机密性保障</li><li>缺乏完整性验证</li></ul><h3 id="安全风险"><a href="#安全风险" class="headerlink" title="安全风险"></a>安全风险</h3><p>由底向上：</p><p>设备破坏，侦听<br>MAC欺骗 泛洪<br>IP欺骗 ICMP攻击<br>TCP欺骗 TCP UDP拒绝服务<br>漏洞 缓冲区溢出</p><h3 id="网络的基本攻击模式"><a href="#网络的基本攻击模式" class="headerlink" title="网络的基本攻击模式"></a>网络的基本攻击模式</h3><ul><li>截获<ul><li>嗅探</li><li>监听</li></ul></li><li>篡改<ul><li>数据包篡改</li></ul></li><li>中断<ul><li>拒绝服务</li></ul></li><li>伪造<ul><li>欺骗</li></ul></li></ul><h3 id="信息安全的五要素"><a href="#信息安全的五要素" class="headerlink" title="信息安全的五要素"></a>信息安全的五要素</h3><ul><li>保密性</li><li>完整性</li><li>可用性</li><li>可控性</li><li>不可否认性</li></ul><p>安全实现：</p><ul><li>行为审计</li><li>授权访问</li><li>身份认证</li><li>数据加密</li></ul><hr><h2 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h2><h3 id="VPN概述"><a href="#VPN概述" class="headerlink" title="VPN概述"></a>VPN概述</h3><p><strong>VPN定义</strong>：</p><blockquote><p>依靠ISP或者NSP在公用网络基础设施上构建的专用的安全数据通信网络。</p></blockquote><p><strong>核心技术</strong>： <code>隧道技术</code></p><p><strong>VPN分类</strong>：</p><ul><li>Access VPN</li><li>LAN-LAN VPN</li></ul><p>IPSec GRE 位于网络层、SSL位于应用层、L2TP PPTP位于网络接口层。</p><p><strong>常用技术</strong>：</p><ol><li>隧道技术</li><li>加解密技术<ul><li>对称加密  IDEA <code>AES</code> RC <code>DES</code></li><li>非对称加密 ECCC <code>RSA</code> Rabin Elgamal</li></ul></li><li>身份认证技术<br> PKI体系，CA认证中心管理（Certificate Authority）。<br> 实例：HTTPS</li></ol><h3 id="IPSec"><a href="#IPSec" class="headerlink" title="IPSec"></a>IPSec</h3><p><strong>开放的协议族</strong>：<br><img src="https://blog-1252404748.cos.ap-chengdu.myqcloud.com/images/IPSec%E5%8D%8F%E8%AE%AE%E6%97%8F.png" alt="IPSec架构"></p><p><strong>IPSec工作模式</strong>：</p><ol><li>传输模式<br> 主机到主机之间，子啊包头后面插IPSec包头</li><li>隧道模式<br> 私网与私网之间，添加新的IP头和IPSec头</li></ol><p><strong>通信协议</strong>：</p><ol><li>AH  Authentication Header 协议号51<ul><li>无连接数据完整性</li><li>数据源认证</li><li>抗重放服务</li></ul></li><li>ESP 封装安全有效载荷 （DES AES）  协议号50<ul><li>AH的功能</li><li>数据保密</li><li>有限的数据流保护</li></ul></li></ol><p><strong>IKE协商</strong>：<br>为IPSec协商生成密钥，建立SA Security Association<br>两个阶段：</p><ul><li>IKE阶段1<ul><li>主模式<br>  SA交换、密钥交换、IP交换及验证，使用6条ISAKMP</li><li>野蛮模式 Aggressive<br>  三个交互包</li></ul></li><li>IKE阶段2<br>  协商IPSec参数</li></ul><p><strong>DPD解决VPN隧道黑洞</strong>： 超时计时器</p><p><strong>注意：</strong></p><ul><li>NAT下，只有ESP 隧道模式可用</li><li>NAT-T解决多个IPSec VPN （为ESP增加了UDP头）</li></ul><p><strong>深信服VPN优势</strong>：</p><ol><li>WebAgent （自动寻址</li><li>更细致的权限粒度</li><li>线路探测</li></ol><hr><h2 id="第三章"><a href="#第三章" class="headerlink" title="第三章"></a>第三章</h2><h3 id="上网行为安全"><a href="#上网行为安全" class="headerlink" title="上网行为安全"></a>上网行为安全</h3><p><strong>上网行为管理</strong>：</p><ol><li>用户认证</li><li>网页过滤</li><li>应用控制</li><li>流量管理</li><li>行为审计</li></ol><p><strong>互联网上网行为管控</strong>：</p><p>路由或网桥部署</p><ol><li>URL过滤+应用封堵</li><li>动态流控+P2P智能流控</li><li>基于网站等进行审计</li></ol><p><strong>一体化网关</strong></p><p><strong>无线wifi管控</strong>：</p><p>portal服务器上进行认证</p><p><strong>无线防共享上网</strong>：</p><p>网关或网桥模式部署在出口主干线路。</p><h3 id="上网行为组网方案"><a href="#上网行为组网方案" class="headerlink" title="上网行为组网方案"></a>上网行为组网方案</h3><p>问题思考:</p><ul><li>AC路由模式部署，不知道接口地址，如何登陆</li><li>如何恢复admin账号密码</li><li>恢复出厂设置</li></ul><p><strong>路由部署解决方案</strong></p><p>AC支持路由、网桥、旁路<br>SG支持路由、网桥、旁路、单臂</p><ul><li>路由模式<br>  NAT VPN DHCP等功能，必须以路由模式</li><li>网桥模式<br>  相当于透明设备 —— 过滤 非TCP控制 SSL内容识别等等</li><li>旁路模式<br>  主要用于审计，对原有网络无影响  —— 静态路由 数据中心</li></ul><p><strong>TRUNK部署解决方案</strong></p><p>VLAN：</p><p>802.1q  单臂路由（子接口） 可用上网行为管理设备AC替换路由</p><p><strong>防火墙过滤规则</strong></p><p>防火墙规则是控制设备各个网口转发数据的开关。</p><p><strong>端口映射</strong></p><p>DNAT  LAN-LAN端口映射（允许公网用户通过公网地址访问内部服务器）</p><h3 id="用户认证技术"><a href="#用户认证技术" class="headerlink" title="用户认证技术"></a>用户认证技术</h3><ul><li>不需要认证</li><li>IP-MAC绑定认证<br>  SNMP网络管理标准  MIB库 管理信息库，SNMP的5中协议数据单元PDU（SNMP管理程序（UDP162）和代理程序（UDP161）之间：<ol><li>get-request</li><li>get-next-request</li><li>set-request</li><li>get-response</li><li>trap 代理进程主动发出的报文<br>30位掩码，只有2个可用IP，AC网桥上下都要分配IP，AC无IP，不能用。</li></ol></li><li>密码认证技术<br>  HTTP协议，GET/HTTP，八种方法（GET POST DELETE CONNECT HEAD PUT TRACE OPTION）<br>  AC拦截GET请求，伪装成服务器，发包，HTTP302 重定向——虚拟IP重定向（网桥模式）DMZ口重定向（无网桥）</li><li>外部认证技术<br>  LDAP认证</li><li>用户和用户组管理</li></ul><h3 id="应用控制技术"><a href="#应用控制技术" class="headerlink" title="应用控制技术"></a>应用控制技术</h3><p><strong>应用特征识别</strong></p><p>数据包五元组（源IP，目的IP，源端口，目的端口，协议）</p><p>深度行为检测：</p><ul><li>深度包检测技术 DPI</li><li>深度流检测技术 DFI   （RTP流  P2P流）</li><li>基于应用层网关的检测 ALG</li><li>基于行为模式的检测</li></ul><p><strong>HTTP识别控制</strong></p><p>重定向</p><p><strong>HTTPS识别控制</strong></p><p>HTTPS封堵，四次握手的第一阶段，识别Client hello报文中的server_name字段</p><p><strong>自定义应用方法</strong></p><h3 id="终端识别和管理技术"><a href="#终端识别和管理技术" class="headerlink" title="终端识别和管理技术"></a>终端识别和管理技术</h3><p><strong>防共享识别和控制</strong></p><p>传统防共享——</p><ul><li>ID轨迹检测</li><li>时钟偏移检测</li><li>流量/连接数统计</li><li>MAC地址检测（淘汰）</li><li>TTL检测</li></ul><p>深信服DPI： </p><ul><li>分析数据包 提取客户端IP</li><li>深信服字体检测</li><li>辅助检测（URL 微信特征ID）</li><li><p><strong>移动终端间共享方案</strong></p></li><li><p>URL检测</p></li><li>应用规则检测</li><li>UA检测 user-agent</li></ul><p><strong>PC和移动终端共享</strong></p><ul><li>URL检测</li><li>应用规则检测</li></ul><p><strong>移动终端解决方案</strong></p><ul><li>URL</li><li>应用规则</li><li>UA检测</li></ul><h3 id="流量管理技术"><a href="#流量管理技术" class="headerlink" title="流量管理技术"></a>流量管理技术</h3><p>传统流量管理，基于Qos，五元组</p><p><strong>主流的流量管控技术</strong>：</p><ul><li>流量监测<ul><li>主动</li><li>被动</li></ul></li><li>应用检测<ul><li>常用端口</li><li>深度流 DFI</li><li>深度包 DPI</li></ul></li><li>应用控制</li><li>识别控制组网<ul><li>直路串联</li><li>旁路干扰</li></ul></li></ul><p><strong>流量控制系统</strong>：</p><ul><li>流量分类</li><li>队列管理</li><li>分组调度</li><li>流量整形 （漏桶 令牌桶）</li></ul><p><strong>SANGFOR</strong>：</p><ul><li>缓存流控</li><li>队列调度</li><li>单用户流量公平调整</li></ul><h3 id="内容审计技术"><a href="#内容审计技术" class="headerlink" title="内容审计技术"></a>内容审计技术</h3><ul><li>上网行为审计</li><li>外发邮件审计</li><li>SSL内容解密审计</li><li>WEB关键字过滤</li><li>IM聊天内容审计</li></ul><hr><h2 id="下一代防火墙"><a href="#下一代防火墙" class="headerlink" title="下一代防火墙"></a>下一代防火墙</h2><p><strong>相关技术</strong></p><ul><li>包过滤<ul><li>检查包头</li></ul></li><li>会话<ul><li>会话表项</li></ul></li><li>应用代理<ul><li>只检查数据</li></ul></li></ul><p><strong>性能指标</strong></p><ul><li>吞吐量</li><li>时延</li><li>丢包率</li><li>背靠背（缓冲容量的大小）</li><li>并发连接数</li></ul><p><strong>深信服下一代</strong>：</p><p>安全可视  持续检测</p><p>融合安全  系统架构</p><h2 id="暂时就做这些-复赛已经结束了"><a href="#暂时就做这些-复赛已经结束了" class="headerlink" title="暂时就做这些 复赛已经结束了"></a>暂时就做这些 复赛已经结束了</h2><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;准备深信服复赛。主要侧重安全部分（深信服是一家做安全的公司啊）。&lt;/p&gt;
    
    </summary>
    
      <category term="Notes" scheme="https://ykksmile.top/categories/Notes/"/>
    
      <category term="比赛" scheme="https://ykksmile.top/categories/Notes/%E6%AF%94%E8%B5%9B/"/>
    
    
      <category term="ComputerNetwork" scheme="https://ykksmile.top/tags/ComputerNetwork/"/>
    
  </entry>
  
  <entry>
    <title>计算机网络面试知识点总结</title>
    <link href="https://ykksmile.top/posts/54431/"/>
    <id>https://ykksmile.top/posts/54431/</id>
    <published>2018-06-11T09:16:56.000Z</published>
    <updated>2018-07-04T02:09:58.989Z</updated>
    
    <content type="html"><![CDATA[<p>一方面是在找工作之前对计算机网络/通信网络的回顾，另一方面准备深信服网络技术大赛。基于《计算机网络》第五版。</p><a id="more"></a><hr><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><h3 id="网络硬件"><a href="#网络硬件" class="headerlink" title="网络硬件"></a>网络硬件</h3><p>点到点 p2p<br>单播 unicasting<br>广播 broadcasting<br>组播 multicasting</p><h4 id="个域网-PAN"><a href="#个域网-PAN" class="headerlink" title="个域网 PAN"></a>个域网 PAN</h4><h4 id="局域网-LAN"><a href="#局域网-LAN" class="headerlink" title="局域网 LAN"></a>局域网 LAN</h4><p>接入点 AP access point<br>无线路由器 wireless router<br>基站 base station<br>WiFi IEEE 802.111<br>以太网 Ethernet 802.3</p><h4 id="域域网-MAN"><a href="#域域网-MAN" class="headerlink" title="域域网 MAN"></a>域域网 MAN</h4><h4 id="广域网-WAN"><a href="#广域网-WAN" class="headerlink" title="广域网 WAN"></a>广域网 WAN</h4><p>主机 host<br>子网 subnet<br>交换机 switch<br>路由器 router<br>ISP internet service provider<br>路由算法  转发算法</p><h4 id="互联网络"><a href="#互联网络" class="headerlink" title="互联网络"></a>互联网络</h4><h3 id="网络软件"><a href="#网络软件" class="headerlink" title="网络软件"></a>网络软件</h3><p>网络体系结构 network architecture<br>协议栈 protocol stack</p><h4 id="层次设计"><a href="#层次设计" class="headerlink" title="层次设计"></a>层次设计</h4><p>检错编码 error detection<br>纠错编码 error correction<br>路由 routing<br>寻址 addressing<br>命名 naming<br>统计复用 statistical multiplexing<br>拥塞 congestion<br>服务质量 qos queality of service</p><h4 id="面向连接和无连接"><a href="#面向连接和无连接" class="headerlink" title="面向连接和无连接"></a>面向连接和无连接</h4><h4 id="服务原语"><a href="#服务原语" class="headerlink" title="服务原语"></a>服务原语</h4><h4 id="服务与协议"><a href="#服务与协议" class="headerlink" title="服务与协议"></a>服务与协议</h4><h3 id="参考模型"><a href="#参考模型" class="headerlink" title="参考模型"></a>参考模型</h3><h4 id="OSI"><a href="#OSI" class="headerlink" title="OSI"></a>OSI</h4><ul><li>物理层 physical layer</li><li>数据链路层 data link layer</li><li>网络层 network layer</li><li>传输层 transport layer</li><li>会话层 session layer</li><li>表示层 presentation layer</li><li>应用层 application layer</li></ul><h4 id="TCP-IP"><a href="#TCP-IP" class="headerlink" title="TCP/IP"></a>TCP/IP</h4><ul><li>链路层</li><li>互联网层</li><li>传输层</li><li>应用层</li></ul><p>最终模型 </p><ul><li>物理层</li><li>数据链路层</li><li>网络层</li><li>传输层</li><li>应用层</li></ul><p>OSI 7层   TCP/IP 4层</p><h3 id="网络实例"><a href="#网络实例" class="headerlink" title="网络实例"></a>网络实例</h3><h4 id="因特网"><a href="#因特网" class="headerlink" title="因特网"></a>因特网</h4><ul><li>ARPANET</li><li>NSFNET</li></ul><p>Internet体系结构</p><p>连接到ISP：DSL Digital Subscriber Line</p><h4 id="3G"><a href="#3G" class="headerlink" title="3G"></a>3G</h4><p>宽带码分多址 WCDMA wideband code division multiple access<br>无线网络控制器 RNC radio network controller<br>核心网 core network<br>LTE long term evolution</p><h4 id="802-11"><a href="#802-11" class="headerlink" title="802.11"></a>802.11</h4><p>无线局域网</p><p>正交频分复用 OFDM orthogonal frequency division multiplexing<br>载波侦听多路访问 CSMA carrier sense multiple access</p><h4 id="RFID-传感器"><a href="#RFID-传感器" class="headerlink" title="RFID 传感器"></a>RFID 传感器</h4><h3 id="网络标准化"><a href="#网络标准化" class="headerlink" title="网络标准化"></a>网络标准化</h3><p>ITU international telecommunication union<br>ISO international standards organization</p><h2 id="物理层"><a href="#物理层" class="headerlink" title="物理层"></a>物理层</h2><h3 id="理论基础"><a href="#理论基础" class="headerlink" title="理论基础"></a>理论基础</h3><h4 id="傅里叶分析和带宽"><a href="#傅里叶分析和带宽" class="headerlink" title="傅里叶分析和带宽"></a>傅里叶分析和带宽</h4><p>带宽 bandwidth<br>基带 baseband</p><h4 id="信道最大传输速率"><a href="#信道最大传输速率" class="headerlink" title="信道最大传输速率"></a>信道最大传输速率</h4><p>尼奎斯特定理<br>香农公式 最大比特率 = Blog2（1+S/N） B带宽 S/N 信噪比</p><h4 id="传输介质"><a href="#传输介质" class="headerlink" title="传输介质"></a>传输介质</h4><ul><li>双绞线 twisted pair</li><li>同轴电缆 coaxial cable</li><li>fiber</li></ul><h3 id="无线传输"><a href="#无线传输" class="headerlink" title="无线传输"></a>无线传输</h3><p>宽频技术：</p><ul><li>跳频扩频</li><li>直接序列扩频</li><li>超宽带通信 UWB</li></ul><h3 id="无线电-微波-红外-光通信-卫星"><a href="#无线电-微波-红外-光通信-卫星" class="headerlink" title="无线电 微波 红外 光通信 卫星"></a>无线电 微波 红外 光通信 卫星</h3><h3 id="数字调制与多路复用"><a href="#数字调制与多路复用" class="headerlink" title="数字调制与多路复用"></a>数字调制与多路复用</h3>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一方面是在找工作之前对计算机网络/通信网络的回顾，另一方面准备深信服网络技术大赛。基于《计算机网络》第五版。&lt;/p&gt;
    
    </summary>
    
      <category term="就业" scheme="https://ykksmile.top/categories/%E5%B0%B1%E4%B8%9A/"/>
    
      <category term="ComputerNetwork" scheme="https://ykksmile.top/categories/%E5%B0%B1%E4%B8%9A/ComputerNetwork/"/>
    
    
      <category term="ComputerNetwork" scheme="https://ykksmile.top/tags/ComputerNetwork/"/>
    
  </entry>
  
  <entry>
    <title>记一次参加dorahacks黑客马拉松的经历</title>
    <link href="https://ykksmile.top/posts/8806/"/>
    <id>https://ykksmile.top/posts/8806/</id>
    <published>2018-06-07T07:05:05.000Z</published>
    <updated>2018-06-12T07:07:39.012Z</updated>
    
    <content type="html"><![CDATA[<p>在6月2号，参加了dorahacks的黑客马拉松活动，即连续24小时编程比赛，打造一款产品。整体来说比赛一般，参与人数很少，并且小团体严重，后期感觉有互相换票的嫌疑，不过对于我自己来说，临时学习了区块链的知识，并与师弟一起，利用24小时，从零开发了一款基于区块链的APP（我负责后台，师弟负责前台）。</p><a id="more"></a><hr><h2 id="仓库地址"><a href="#仓库地址" class="headerlink" title="仓库地址"></a>仓库地址</h2><p><a href="https://github.com/cloisonne/blockchain" target="_blank" rel="noopener">基于区块链的记忆app的服务端</a><br><a href="https://github.com/cloisonne/Drifting" target="_blank" rel="noopener">基于区块链的心情漂流APP </a></p><hr><h2 id="针对blockchain做的改进"><a href="#针对blockchain做的改进" class="headerlink" title="针对blockchain做的改进"></a>针对blockchain做的改进</h2><h3 id="增加block属性"><a href="#增加block属性" class="headerlink" title="增加block属性"></a>增加block属性</h3><p>改进了block属性，以与记忆app（一款基于区块链的心情分享、漂流瓶社交应用）配合。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">new_block</span><span class="params">(self, proof: int, my_message: str, previous_hash: Optional[str])</span> -&gt; Dict[str, Any]:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    生成新块</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :参数proof: 工作量证明算法给出的证明</span></span><br><span class="line"><span class="string">    :参数previous_hash: 上一个块的哈希值</span></span><br><span class="line"><span class="string">    :return: 一个新块</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    block = &#123;</span><br><span class="line">        <span class="string">'index'</span>: len(self.chain) + <span class="number">1</span>,</span><br><span class="line">        <span class="string">'my_message'</span>: my_message,</span><br><span class="line">        <span class="string">'timestamp'</span>: time(),</span><br><span class="line">        <span class="string">'transactions'</span>: self.current_transactions,</span><br><span class="line">        <span class="string">'proof'</span>: proof,</span><br><span class="line">        <span class="string">'previous_hash'</span>: previous_hash <span class="keyword">or</span> self.hash(self.chain[<span class="number">-1</span>]),</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h3 id="加入web端，与flask交互"><a href="#加入web端，与flask交互" class="headerlink" title="加入web端，与flask交互"></a>加入web端，与flask交互</h3><p>php实现 需要搭建apache+php环境。</p><h3 id="修改了挖矿等方法的method"><a href="#修改了挖矿等方法的method" class="headerlink" title="修改了挖矿等方法的method"></a>修改了挖矿等方法的method</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.route('/mine', methods=['GET','POST'])</span></span><br></pre></td></tr></table></figure><h3 id="post-test"><a href="#post-test" class="headerlink" title="post_test"></a>post_test</h3><p>用于模拟post，发送挖矿请求。</p><hr><h2 id="PHP界面的实现"><a href="#PHP界面的实现" class="headerlink" title="PHP界面的实现"></a>PHP界面的实现</h2><p>效果如图：</p><p><img src="https://blog-1252404748.cos.ap-chengdu.myqcloud.com/images/php-blockchain.png" alt="区块链前端"></p><p>基于folk的php代码，根据flask后台改造了区块链前端。</p><figure class="highlight php"><table><tr><td class="code"><pre><span class="line">&lt;div align=<span class="string">"center"</span>&gt;</span><br><span class="line">&lt;form class="form-inline" action="index.php?port=&lt;?php echo $_REQUEST["port"]?&gt;&amp;mine=1" method="POST"&gt;</span><br><span class="line">  &lt;div class="form-group"&gt;</span><br><span class="line">&lt;label &gt;输入message：&lt;/label&gt;</span><br><span class="line">&lt;input type="text" class="form-control" id="my_message" name="my_message"&gt;</span><br><span class="line">  &lt;/div&gt;</span><br><span class="line">  &lt;button type="submit" class="btn btn-primary"&gt;发送消息&lt;/button&gt;</span><br><span class="line">&lt;/form&gt;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在6月2号，参加了dorahacks的黑客马拉松活动，即连续24小时编程比赛，打造一款产品。整体来说比赛一般，参与人数很少，并且小团体严重，后期感觉有互相换票的嫌疑，不过对于我自己来说，临时学习了区块链的知识，并与师弟一起，利用24小时，从零开发了一款基于区块链的APP（我负责后台，师弟负责前台）。&lt;/p&gt;
    
    </summary>
    
      <category term="Notes" scheme="https://ykksmile.top/categories/Notes/"/>
    
      <category term="比赛" scheme="https://ykksmile.top/categories/Notes/%E6%AF%94%E8%B5%9B/"/>
    
    
      <category term="区块链" scheme="https://ykksmile.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="PHP" scheme="https://ykksmile.top/tags/PHP/"/>
    
      <category term="安卓" scheme="https://ykksmile.top/tags/%E5%AE%89%E5%8D%93/"/>
    
  </entry>
  
  <entry>
    <title>车牌识别工作时间轴</title>
    <link href="https://ykksmile.top/posts/19204/"/>
    <id>https://ykksmile.top/posts/19204/</id>
    <published>2018-06-05T11:46:23.000Z</published>
    <updated>2018-11-02T03:22:53.766Z</updated>
    
    <content type="html"><![CDATA[<p>最近放弃了带遮挡的人脸识别，投身车牌识别的大业，这里的车牌识别是基于国内的、多种类的、恶劣条件下的，可以成为Real or Wild的plate recognition，将时间线和所做工作总结如下，主要同步自实验室的私有gitlab。</p><a id="more"></a><hr><h2 id="说下gitlab"><a href="#说下gitlab" class="headerlink" title="说下gitlab"></a>说下gitlab</h2><p>恰巧guyhub被微软收购了，未来可能会退出CN版的guyhub，当然如果是这样，外网guyhub应该是访问不了了，而国内的服务一定是遵守社会主义核心价值观，像host这样的开源库可能就要被灭绝了。</p><p>我们实验室内部代码交流和项目协作主要使用gitlab，一方面代码不便于在github公开仓库上共享，另一方面放着服务器不搭个写代码的平台也说不过去。gitlab的功能一定是比github更强大更丰富的，目前使用的功能还是比较少，对于git比较熟，所以也算得心应手。</p><hr><h2 id="开源库HyperLPR"><a href="#开源库HyperLPR" class="headerlink" title="开源库HyperLPR"></a>开源库HyperLPR</h2><p><a href="https://github.com/zeusees/HyperLPR" target="_blank" rel="noopener">HyperLPR</a>是基于深度学习的高性能中文车牌识别开源库，这里做一些研究，目前发现的问题有：</p><ul><li>EasyPR的数据集准确率并不高，大概60%？远达不到宣称的90%</li><li>框架使用深度学习，训练网络时数据集应该不够多，效果差强人意</li></ul><p>目前发现的优点有：</p><ul><li>端到端的神经网络训练模型进行车牌字符识别</li><li>代码比较轻量</li></ul><h3 id="工作流程分析"><a href="#工作流程分析" class="headerlink" title="工作流程分析"></a>工作流程分析</h3><p>对HyperLPR一个完整的车牌识别工作流程进行分析：</p><ol><li>batch.py  批量处理工具 批量读取文件调用pipline</li><li>pipline调用SimpleRecognizePlate函数（SimpleRecognizePlateByE2E ？）</li><li>detectPlateRough 传入灰度图 参数如下<ul><li>resize_h </li><li>en_scale</li><li>top_bottom_padding_rate</li></ul></li><li>调用模型’./model/cascade.xml’ 使用opencv中CascadeClassifier的detectMultiScale多尺度检测</li><li>车牌粗定位完成 进行SimplePredict 使用”./model/plate_type.h5”模型确定车牌类别（神经网络）</li><li>如果车型判断成功 对车牌进行bitwise_not二值化反色处理</li><li>调用finemapping中的精定位算法findContoursAndDrawBoundingBox</li><li>调用finemapping中的”./model/model12.h5”左右边界回归  进行垂直精定位算法finemappingVertical</li><li>调用e2e 使用模型”./model/ocr_plate_all_w_rnn_2.h5” 端到端字符识别  只输出不使用？</li><li>校正完成 使用segmentation中的slidingWindowsEval 进行文字分割和识别</li><li>置信度判断和输出</li></ol><p>注意事项：</p><ul><li>ocr_plate_all_gru.h5 作为序列模型效果更好，但是更慢  以上过程中未使用</li></ul><h3 id="思路整理和细节分析"><a href="#思路整理和细节分析" class="headerlink" title="思路整理和细节分析"></a>思路整理和细节分析</h3><h4 id="车牌粗定位"><a href="#车牌粗定位" class="headerlink" title="车牌粗定位"></a>车牌粗定位</h4><ol><li>读取图像，进行resize，高度720，cvtColor转化为灰度图</li><li>cascade多尺度检测<br> cascade模型如何训练的？<br> Opencv的Haar级联分类目标检测器，使用<a href="https://github.com/zeusees/train-detector" target="_blank" rel="noopener">train-detector</a>，需要正样本和负样本，正样本使用现有车牌识别软件crop，误检区域也加入负样本。<br> cascade是通过多个adaboost强分类串联得到一个新的分类器，只有所有的adaboost分类器都认为是positive，最终结果才是positive，否则都是negative，以此大幅降低FP rate，而TP rate基本不变。</li><li>剪切crop</li></ol><h4 id="车牌精定位"><a href="#车牌精定位" class="headerlink" title="车牌精定位"></a>车牌精定位</h4><ol><li>上下边界</li><li>左右边界</li></ol><h4 id="车牌颜色识别"><a href="#车牌颜色识别" class="headerlink" title="车牌颜色识别"></a>车牌颜色识别</h4><ol><li>reshape成3行矩阵，用KMeans聚类</li><li>画直方图，找出数目最多的聚类中心</li><li>对该点进行颜色识别</li></ol><h4 id="数据生成和增强"><a href="#数据生成和增强" class="headerlink" title="数据生成和增强"></a>数据生成和增强</h4><ol><li>使用label和template</li><li>增加脏污效果，生成脏污块，使用cv2.addweighted图片融合</li><li>轻微畸变，cv2.warpPerspective</li><li>分三个通道增加noise</li><li>5w张车牌</li></ol><h4 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h4><ol><li>使用端到端的级联CNN模型，模型结构：级联的Conv2D卷积，kernel size分别为32 64 128 256 1024，前几层使用relu激活，最后一层使用softmax，数量为num_char+1</li></ol><h4 id="车牌识别"><a href="#车牌识别" class="headerlink" title="车牌识别"></a>车牌识别</h4><h3 id="测试程序"><a href="#测试程序" class="headerlink" title="测试程序"></a>测试程序</h3><p>完整修改了测试程序，并进行了正确率测试，大部分特殊车牌不支持，少数几种车牌识别率低于20%。</p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plate_recogniton</span><span class="params">(real_path)</span>:</span></span><br><span class="line">    plate_real = real_path[:<span class="number">-4</span>].split(<span class="string">'\\'</span>)[<span class="number">-1</span>][:<span class="number">8</span>]</span><br><span class="line">    plate_real_list.append(plate_real)</span><br><span class="line">    print(<span class="string">'plate_real:'</span> + str(plate_real))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> real_path.endswith(<span class="string">".jpg"</span>) <span class="keyword">or</span> real_path.endswith(<span class="string">".png"</span>) <span class="keyword">or</span> real_path.endswith(<span class="string">".JPG"</span>):</span><br><span class="line">        image =  cv_imread(real_path)</span><br><span class="line">        <span class="comment"># print(type(image))</span></span><br><span class="line">        <span class="comment"># image,res  = model.SimpleRecognizePlateByE2E(image)</span></span><br><span class="line">        res = model.SimpleRecognizePlateByE2E(image)</span><br><span class="line">        max_res = [<span class="string">'null'</span>,<span class="number">0</span>,[<span class="number">862.01999999999998</span>, <span class="number">924.0</span>, <span class="number">178.03504678726196</span>, <span class="number">52.0</span>]]</span><br><span class="line">        res.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>],reverse=<span class="keyword">True</span>)</span><br><span class="line">        <span class="keyword">if</span> len(res) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">elif</span> len(res) &gt;= <span class="number">1</span>:</span><br><span class="line">            max_res = res[<span class="number">0</span>]</span><br><span class="line">        print(res)</span><br><span class="line">        plate_predict = max_res[<span class="number">0</span>]</span><br><span class="line">        print(<span class="string">'plate_predict:'</span> + plate_predict)</span><br><span class="line">        plate_predict_list.append(plate_predict)</span><br></pre></td></tr></table></figure><h3 id="车牌生成"><a href="#车牌生成" class="headerlink" title="车牌生成"></a>车牌生成</h3><p>使用<a href="https://github.com/LCorleone/hyperlpr-train_e2e" target="_blank" rel="noopener">hyperlpr-train_e2e</a></p><p>具体代码和训练模板稍后放出。</p><h3 id="模型的训练程序"><a href="#模型的训练程序" class="headerlink" title="模型的训练程序"></a>模型的训练程序</h3><p>使用<a href="https://github.com/armaab/hyperlpr-train" target="_blank" rel="noopener">Hyperlpr端到端车牌识别训练脚本</a></p><p>一个encoding问题：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.labels = []</span><br><span class="line">    <span class="keyword">with</span> open(self._label_file,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:   <span class="comment"># 强制utf-8</span></span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            filename, label = parseLine(line)</span><br><span class="line">            self.filenames.append(filename)</span><br><span class="line">            self.labels.append(label)</span><br><span class="line">            self._num_examples += <span class="number">1</span></span><br><span class="line">    self.labels = np.float32(self.labels)</span><br></pre></td></tr></table></figure><p>代码跑出来loss到30%，在titan上大约30秒一个epoch</p><p>需要改进的：</p><ul><li>输出acc</li><li>输出网络模型</li></ul><h3 id="框架的改进思路"><a href="#框架的改进思路" class="headerlink" title="框架的改进思路"></a>框架的改进思路</h3><p>尝试使用GRU模型，但图片的输入格式有问题，训练loss不降反升？</p><p><strong>keras仍然不够熟悉，需要继续学习。</strong></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近放弃了带遮挡的人脸识别，投身车牌识别的大业，这里的车牌识别是基于国内的、多种类的、恶劣条件下的，可以成为Real or Wild的plate recognition，将时间线和所做工作总结如下，主要同步自实验室的私有gitlab。&lt;/p&gt;
    
    </summary>
    
      <category term="Notes" scheme="https://ykksmile.top/categories/Notes/"/>
    
      <category term="比赛" scheme="https://ykksmile.top/categories/Notes/%E6%AF%94%E8%B5%9B/"/>
    
    
      <category term="Python" scheme="https://ykksmile.top/tags/Python/"/>
    
      <category term="MachineLearning" scheme="https://ykksmile.top/tags/MachineLearning/"/>
    
      <category term="DeepLearning" scheme="https://ykksmile.top/tags/DeepLearning/"/>
    
      <category term="PlateRecogniton" scheme="https://ykksmile.top/tags/PlateRecogniton/"/>
    
  </entry>
  
  <entry>
    <title>2018华为网赛云主机操作合集</title>
    <link href="https://ykksmile.top/posts/14112/"/>
    <id>https://ykksmile.top/posts/14112/</id>
    <published>2018-05-18T11:17:36.000Z</published>
    <updated>2018-06-05T11:45:57.289Z</updated>
    
    <content type="html"><![CDATA[<p>在华为2018网络技术大赛中拿到了全国亚军，3个小时的配置任务（包括华为manageone平台、fuisoninsight大数据平台、云主机操作），除了最后hue上的数据库操作比较费时，总共花了1个小时多一点就配完了，还是不错的成绩。这一篇是赛前整理的一些配置的linux命令。</p><a id="more"></a><hr><p>华为使用的云主机平台为SUSE Linux Enterprise servers，这里记一些网络决赛常用命令。</p><h2 id="文档分工"><a href="#文档分工" class="headerlink" title="文档分工"></a>文档分工</h2><p>肖 : FusionInsight HD V100R002C70SPC200 业务操作指南 02</p><p>zookeeper   yarn  mapreduce  hive  HDFS</p><p>董 ： ManageOne ServiceCenter 3.0.8 高危操作一览表 01</p><p>郭 ： ManageOne ServiceCenter 3.0.8 告警处理 01</p><p>需要分出去的： </p><p>FusionInsight HD V100R002C70SPC200 产品描述 02  企业级增强特性</p><h2 id="Linux命令"><a href="#Linux命令" class="headerlink" title="Linux命令"></a>Linux命令</h2><p><a href="http://man.linuxde.net/" target="_blank" rel="noopener">Linux命令大全</a></p><h3 id="用户管理"><a href="#用户管理" class="headerlink" title="用户管理"></a>用户管理</h3><p><a href="https://www.linuxidc.com/Linux/2016-10/136251.htm" target="_blank" rel="noopener">用户和用户组以及 Linux 权限管理</a></p><h4 id="etc-passwd-中的字段"><a href="#etc-passwd-中的字段" class="headerlink" title="/etc/passwd 中的字段"></a>/etc/passwd 中的字段</h4><ul><li>ACCOUNT：用户名</li><li>PASSWORD：密码占位符</li><li>UID：用户ID</li><li>GID：用户组ID</li><li>COMMAND：注释信息</li><li>HOME DIR：用户家目录</li><li>SHELL：用户的默认 shell</li></ul><h4 id="添加用户"><a href="#添加用户" class="headerlink" title="添加用户"></a>添加用户</h4><ul><li>useradd -u UID：指定 UID，这个 UID 必须是大于等于500，并没有其他用户占用的 </li><li>UID useradd -g  GID/GROUPNAME：指定默认组，可以是 GID 或者 GROUPNAME，同样也必须真实存在</li><li>useradd -G  GROUPS：指定额外组 </li><li>useradd -c COMMENT：指定用户的注释信息 </li><li>useradd -d PATH：指定用户的家目录</li><li>useradd -s SHELL：指定用户的默认 shell，最好是在 /etc/shells 中存在的路径 </li><li>useradd -s /sbin/nologin：该用户不能登录，还记得我们上面说到的系统用户不能登录吧？我们可以看到系统用户的 shell 字段也是</li><li>/sbin/nologin echo $SHELL ：查看当前用户的 shell 类型 useradd -M</li><li>USERNAME：创建用户但不创建家目录 useradd -mk USERNAME：创建用户的同时创建家目录，并复制 /etc/skel中的内容到家目录中。关于 /etc/skel 目录会在下一篇 Linux 权限管理中再次讲解。</li><li>如果用户没有家目录，那么不能切换到该用户</li></ul><h4 id="修改用户信息"><a href="#修改用户信息" class="headerlink" title="修改用户信息"></a>修改用户信息</h4><ul><li>usermod -G GROUPS USERNAME：改变用户的附加组，会完全替换原有的附加组 usermod -G -a GROUPS </li><li>USERNAME：在原有附加组的基础上追加附加组 usermod -d PATH      </li><li>USERNAME：修改家目录。修改后原先家目录中的文件不能访问了，因为在当前的家目录中并不存在这些文件。 usermod -l      </li><li>NEWNAME USERNAME：改变用户名 usermod -e USERNAME：指定该用户的过期时间 </li><li>usermod -L     USERNAME：锁定用户</li><li>usermod -U USERNAME：解锁用户</li></ul><h4 id="其他命令"><a href="#其他命令" class="headerlink" title="其他命令"></a>其他命令</h4><ul><li>id 显示用户属性</li><li>finger 检索用户信息</li><li>userdel 删除  -r删除家目录</li><li>groupadd -g GID GROUPNAME  groupdel   groupmod  gpasswd 组密码</li></ul><h3 id="文件权限"><a href="#文件权限" class="headerlink" title="文件权限"></a>文件权限</h3><h4 id="chmod"><a href="#chmod" class="headerlink" title="chmod"></a>chmod</h4><p> linux文件的用户权限的分析图</p><p>例：rwx　rw-　r–</p><p>r=读取属性　　//值＝4</p><p>w=写入属性　　//值＝2</p><p>x=执行属性　　//值＝1</p><pre><code>chmod u+x,g+w f01　　//为文件f01设置自己可以执行，组员可以写入的权限chmod u=rwx,g=rw,o=r f01chmod 764 f01chmod a+x f01　　//对文件f01的u,g,o都设置可执行属性</code></pre><h4 id="chown"><a href="#chown" class="headerlink" title="chown"></a>chown</h4><p>将目录/usr/meng及其下面的所有文件、子目录的文件主改成 liu：</p><pre><code>chown -R liu /usr/meng</code></pre><h3 id="网络管理"><a href="#网络管理" class="headerlink" title="网络管理"></a>网络管理</h3><h4 id="ifconfig"><a href="#ifconfig" class="headerlink" title="ifconfig"></a>ifconfig</h4><pre><code>ifconfigifconfig eth0 upifconfig eth0 down[root@localhost ~]# ifconfig eth0 192.168.2.10[root@localhost ~]# ifconfig eth0 192.168.2.10 netmask 255.255.255.0[root@localhost ~]# ifconfig eth0 192.168.2.10 netmask 255.255.255.0 broadcast 192.168.2.255</code></pre><h3 id="SLA指标"><a href="#SLA指标" class="headerlink" title="SLA指标"></a>SLA指标</h3><ul><li>df 查看分区</li><li>route -n 路由</li><li>cat /etc/recolv.conf</li><li>ifconfig</li></ul><h3 id="分区管理"><a href="#分区管理" class="headerlink" title="分区管理"></a>分区管理</h3><p><a href="https://blog.csdn.net/beyondlpf/article/details/10147037" target="_blank" rel="noopener">linux 分区 物理卷 逻辑卷</a></p><h4 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h4><pre><code>fdisk -l83 是代表EXT2和EXT382 是代表SWAP分区fdisk   /dev/sda D删除一个分区N创建一个分区Q 不保存退出T改变分区IDW保存退出 partprobemkfs    -t   ext3   /dev/sda7 mkdir   /mnt/backupmount   -t   ext3   /dev/sda7    /mnt/backup mkfs.ext3   /dev/sdaxt  改变分区类型LVM  8el 查看分区类型编号</code></pre><h4 id="创建LVM"><a href="#创建LVM" class="headerlink" title="创建LVM"></a>创建LVM</h4><pre><code>pvcreate   /dev/sdax vgcreate     myvg        /dev/sda8lvcreate  -L  大小  卷组名  -n  逻辑卷名称mkfs.ext3   /dev/myvg/mylv1 mkdir   /mnt/mylv1 mount   -t   ext3   /dev/myvg/mylv1   /mnt/mylv1 lvdisplaylvcreate   -L  150M   myvg   -n   mylv2mkfs.ext3   /dev/myvg/mylv2mkdir   /mnt/mylv2mount   -t   ext3   /dev/myvg/mylv2   /mnt/mylv2 lvresize   -L   绝对大小   对象lvresize   -L   100M   /dev/myvg/mylv2 resize2fs   /dev/myvg/mylv2</code></pre><h2 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h2><h3 id="产品架构"><a href="#产品架构" class="headerlink" title="产品架构"></a>产品架构</h3><p><code>FusionInsight HD V100R002C70SPC200 产品描述 02</code></p><ul><li><p>DBservice<br>  一个具备高可靠性的传统关系型数据库，为Hive、 Hue、 Spark组件提供元数据存储服务。</p></li><li><p>HBase<br>  提供海量数据存储功能，是一种构建在HDFS之上的分布式、面向列的存储系统。</p></li><li><p>HDFS<br>  Hadoop分布式文件系统（Hadoop Distributed File System），提供高吞吐量的数据访问，适合大规模数据集方面的应用。</p></li><li><p>Hive<br>  建立在Hadoop基础上的开源的数据仓库，提供类似SQL的Hive Query Language语言操作结构化数据存储服务和基本的数据分析服务。</p></li><li><p>Hue<br>  提供了FusionInsight HD应用的图形化用户Web界面。 Hue支持展示多种组件，目前支持HDFS、YARN/MapReduce、 Hive和Solr。</p></li><li><p>KrbServer 及 LdapServer<br>  通过KrbServer为所有组件提供Kerberos认证功能，实现了可靠的认证机制。LdapServer支持轻量目录访问协议（Lightweight Directory Access Protocol，简称为LDAP），为Kerberos认证提供用户和用户组数据保存能力。</p></li><li><p>Mapreduce<br>  提供快速并行处理大量数据的能力，是一种分布式数据处理模式和执行环境。</p></li><li><p>Yarn<br>  资源管理系统，它是一个通用的资源模块，可以为各类应用程序进行资源管理和调度。</p></li><li><p>ZooKeeper<br>  提供分布式、高可用性的协调服务能力。帮助系统避免单点故障，从而建立可靠的应用程序。</p></li></ul><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在华为2018网络技术大赛中拿到了全国亚军，3个小时的配置任务（包括华为manageone平台、fuisoninsight大数据平台、云主机操作），除了最后hue上的数据库操作比较费时，总共花了1个小时多一点就配完了，还是不错的成绩。这一篇是赛前整理的一些配置的linux命令。&lt;/p&gt;
    
    </summary>
    
      <category term="Notes" scheme="https://ykksmile.top/categories/Notes/"/>
    
      <category term="比赛" scheme="https://ykksmile.top/categories/Notes/%E6%AF%94%E8%B5%9B/"/>
    
    
      <category term="Linux" scheme="https://ykksmile.top/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>有遮挡的人脸识别论文阅读整理</title>
    <link href="https://ykksmile.top/posts/9363/"/>
    <id>https://ykksmile.top/posts/9363/</id>
    <published>2018-05-14T02:29:36.000Z</published>
    <updated>2018-06-05T11:46:02.036Z</updated>
    
    <content type="html"><![CDATA[<p>暂时决定先跑个RSC，后面需要改进时继续整理论文。</p><a id="more"></a><hr><h2 id="现有研究和背景"><a href="#现有研究和背景" class="headerlink" title="现有研究和背景"></a>现有研究和背景</h2><p>现有的用于解决部分遮挡的人脸识别的方法：</p><ol><li>基于 <code>KL</code>（Karhunen Loeve ,KL）扩展的方法：这类方法对原始训练数据进行预处理，然后通过KL变换求得主成分作为分类的特征，最后用稀疏表示分类 （Sparse Representation Classification，SRC）进行分类。<br>典型的方法包括：<ul><li><code>RSC</code>（Robust Sparse Coding）</li><li><code>LRMA</code>（Low Rank Matrix Approximation） </li><li><code>SDR-SLR</code>（Supervised Low Rank Dictionary Decomposition ,SDR-SLR）将训练数据分离成与身份有关信息、与身份无关信息以及噪声部分，能有效地提高有遮挡的人脸识别率。<br>以上方法强调了在训练数据中结构不协调的重要性，即 尽可能地从独立的不同类中学习到变换矩阵。</li></ul></li><li><del>基于模型的方法： 主要代表方法是基于 3D 模型的人脸识别，这类通过更多的摄像传感器获取人脸的三维模型来进行识别与认证，对于人脸的姿态、表情、 光照、 遮挡等变化都有非常稳健的性能。 Nese Alyuz提出了一种完全自动的三维 人脸识别系统，对遮挡的情况具有鲁棒性。它主要针对表面有遮挡的人脸识别和基于子空间分析技术引起的数据丢失进行分类，利用未被遮挡的部分进行训练，遮挡部分被剔除。在分类阶段采取掩蔽策略，是一种利用不完备数据进行子空间分析的 技术，进一步来说就是用局部处理的方法来改善全局的质量。</del></li><li><del>基于相关的方法： Felix Juefei-Xu 在文章[12]中提出了在表情、遮挡、 姿态变 化下的 3D<br>人脸识别。文章[15]提出了一种新的几何框架，用螺旋弯曲的方法去对 比、匹配、<br>平均化他们的形状并表示面部的表面，去创建一个黎曼结构，用于分析 面部表面的形状。 A. M.<br>Ali[13]提出了一种在远距离框架下姿态不变的 3D 人脸识别 模型。能自动获取图形完成人脸识别。</del></li><li>基于<code>模板</code>的方法： JongJu 在文章[14]中提出了一种在遮挡下对面部特征检测<br>和追踪的方法，初始化阶段、检测人脸、估计面部的姿态，根据检测出来的人脸， 初始化与姿态有关的特征集合；<br>优化阶段将海森矩阵与轮廓梯度向量以及外观误 差联合起来更新参数集，进而获得面部的参数， 通过加入一个模板脸将特征检测延 伸到人脸追踪，<br>使得在重度遮挡的情况下依然能实现更为精确的面部特征识别。</li><li>基于<code>特征</code>的方法： 字符串匹配是一种非常有力的部分匹配技术，但是并不<br>适合正面的人脸识别，因为人脸包括连续和不连续的特征，需要利用全局序列来表 Weiping<br>Chen[16]提出了一种使用全局字符串匹配的人脸识别方法，它利用非常<br>紧凑的语法描述字符串去表示人脸，可以在两张不连续的字符串脸间完成匹配。因 为人脸字符串的相继顺序和方向都不变，<br>这个潜在的性质使得算法在识别过程中 能够自动利用每一块没有被遮挡的区域，而不用去管形状是什么样。 这种方法在训<br>练样本数量很少时同样有效。实验验证上述方法不仅在部分遮挡的人脸识别中有<br>显著的性能，而且有能力将素描的人脸和相片里面的人脸进行匹配。另外一种是<br>Lingfeng[17]提出来的流形正则化的局部稀疏表示方法（MRLSR）， 该方法认为在稀 疏表示条件下所有的编码向量都是组稀疏的。具有个体稀疏和局部相似两条性质。 利用这些性质能有效地提升有部分遮挡情况下的人脸识别率。</li><li>基于<code>神经网络</code>的方法： 随着近几年深度学习研究的深入，基于神经网络的人脸识别研究也获得了许多进步，其中香港中文大学的汤晓鸥团队提出的基于深度学习[18-20]的人脸识别，利用卷积神经网络学习特征，刷新了人脸识别率的新高 峰。 DeepID特征可以从卷积神经网络的最后一个隐藏层提出来，在学习基于卷积 神经网络的分类器时，沿着特征提取的层次结构减少神经元的个数，这个卷积神经网络的顶层神经元个数会逐渐减少，最后只保留几个与身份相关的神经元。 Y. Sun[19]针对人脸识别中很难有效提取到能降低类内变化并增加类间变化的特征这个问 题，提出了 <code>DeepID2</code> 特征。实验证明使用DeepID2 特征能更加有效地提升识别率。 在文章[20]中提出了一种更高性能的卷积神经网络，通过增加隐藏表示的维数并在前面的卷积层加入监督，使得 DeepID2+获得更好的识别率， 实验证明了 DeepID2+ 对于遮挡情况也十分稳健。</li></ol><h2 id="现有数据库："><a href="#现有数据库：" class="headerlink" title="现有数据库："></a>现有数据库：</h2><ol><li>AR 人脸图像数据库： 包含 126 个人的四千多张正面人脸图像，其中男性<br>70 个，女性 56 个。每个人有 26 张人脸图像，其中包含了光照变化、表情变化、<br>还有眼镜遮挡和围巾遮挡。该人脸数据库中的图像分别间隔了两周的时间采集：<br>session1 和 session2，每个时间段每个人采集了 13 张。</li><li>FERET 人脸图像数据库： 美国军方组织的 FERET 人脸识别算法测试[5]，<br>主要为了解决成像条件理想、用户配合、中小规模人脸数据库上的人脸识别问题。<br>该数据库包含有 14,051 张人脸图像， 每张人脸图像有姿态和光照的变化，并且主<br>要为白种人。</li><li>Yale 人脸数据库： 包含有 15 个人的 165 张 GIF 格式的灰度图片， 其中每<br>个人有 11 张人脸图像，包含了丰富的表情变化和光照变化， 比如：快乐、伤心、<br>惊讶、正常、 困倦、眨眼、 左偏光、 中心光、右偏光等。</li><li>Yale 人脸数据库 B： 在 576 个观察条件下（9 种不同姿态64 种光照条件）<br>采集到的 10 个自愿者的 5760 张人脸图像， 即每个自愿者在每一种观察条件下采<br>集到一张人脸图像。</li><li>PIE 人脸数据库： 由 68 个人的的 41368 张人脸图像组成，其中每个人的人<br>脸图像是在 13 种不同姿态、 43 种不同的光照、 4 种不同的表情条件下采集到的。</li><li>SCface 人脸数据库： 由 130 个人的 4060 张静态人脸图像构成， 人脸图像<br>是在室内用五架分辨率不一的摄像机采集的。 SCface 人脸数据库是开源的， 可以<br>很方便的获取。</li><li>LFW 人脸数据库： 该数据库由美国马萨诸塞大学阿姆斯特分校计算机视觉<br>实验室整理完成，主要研究非受限情形下的人脸识别问题，现在已成为学术界乃至<br>工业界评价识别性能的 benchmark。该数据库包含了 5749 个人的 13233 幅人脸图<br>像，这些人脸图像主要是从互联网上收集的，反映了真实场景下的人脸图像，比如<br>大的姿态变化、光照变化、表情变化、任意的遮挡等。</li></ol><h2 id="论文观点整理"><a href="#论文观点整理" class="headerlink" title="论文观点整理"></a>论文观点整理</h2><h3 id="有部分遮挡的人脸识别方法研究"><a href="#有部分遮挡的人脸识别方法研究" class="headerlink" title="有部分遮挡的人脸识别方法研究"></a>有部分遮挡的人脸识别方法研究</h3><p><strong>因为人脸这边不做了，集中精力搞车牌，暂时不更新了。</strong></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;暂时决定先跑个RSC，后面需要改进时继续整理论文。&lt;/p&gt;
    
    </summary>
    
      <category term="Notes" scheme="https://ykksmile.top/categories/Notes/"/>
    
      <category term="比赛" scheme="https://ykksmile.top/categories/Notes/%E6%AF%94%E8%B5%9B/"/>
    
    
      <category term="MachineLearning" scheme="https://ykksmile.top/tags/MachineLearning/"/>
    
      <category term="FaceRecognition" scheme="https://ykksmile.top/tags/FaceRecognition/"/>
    
  </entry>
  
  <entry>
    <title>机器学习路线和清单</title>
    <link href="https://ykksmile.top/posts/17158/"/>
    <id>https://ykksmile.top/posts/17158/</id>
    <published>2018-05-12T03:03:45.000Z</published>
    <updated>2018-06-05T11:44:35.455Z</updated>
    
    <content type="html"><![CDATA[<p>写给师妹的机器学习路线和清单。</p><a id="more"></a><hr><h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>目前这是互联网领域最火的科目之一，一方面是高薪，另一方面是层出不穷的辅导班，未来很难说，不过这绝对是一个容易入门但很难做好做出成绩的方向。</p><p>想要找到一份不错的工作，需要更好的对算法底层的理解，需要刷一些相关的题目，需要有竞赛经验或者顶会论文才可以。</p><p>但是只要努力，总会得到自己想要的吧。</p><h2 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h2><h3 id="周志华的西瓜书《机器学习》"><a href="#周志华的西瓜书《机器学习》" class="headerlink" title="周志华的西瓜书《机器学习》"></a>周志华的西瓜书《机器学习》</h3><p>这本书是很多人推荐给新手的入门书，与此类似的还有吴恩达的机器学习课程，我觉得都很一般，特别是这本书，基本上对新手入门不太友好，但是对于有一定基础的确实可以缩短时间，可以省去很多选择的时间，把精力专注在一本书上，下面是一些推荐学习的tips：</p><ol><li>对于机器学习算法的统筹感官，推荐阅读：<br><a href="https://blog.csdn.net/u011001084/article/details/52523897" target="_blank" rel="noopener">机器学习常用 35 大算法盘点（附思维导图）</a></li><li>基于此，一些学习机器学习所需的前置条件就可以有所了解了，比如概率论、工程优化、基本的关联规则等等，这些内容我建议用到的直接增量学习。</li><li>开始西瓜书的学习，第一遍难点略过，注意把握统筹感受，这个阶段搞不明白损失函数到底是什么实在是很正常的事情，只需要知道一些专业术语，和这些算法是什么即可。</li></ol><h3 id="什么是我最推崇的增量学习？"><a href="#什么是我最推崇的增量学习？" class="headerlink" title="什么是我最推崇的增量学习？"></a>什么是我最推崇的增量学习？</h3><p>例如在logistic对数回归的学习中，需要对公式进行推导，这里用到了高等数学的基本概念；或者对于贝叶斯分类器，这里需要概率论与数理统计的基本概念。重点是，不会这些推导会影响你对算法的整体感知吗，不会的，所以可以选择性略过，节约了大量的时间。如果选择要死啃，此时遇到什么再去学习什么，翻到对应章节，切忌拿一本概率论苦读。</p><h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><p>实战主要是使用python，sklearn库，进行库函数的调取，这里前置条件又很多，如下：</p><ul><li>python语言，会写即可，不需要学习web开发、GUI等第三方模块</li><li>还是学python3，学会了python2也会了</li><li>python的第三方库，包括numpy pandas 还有画图使用的mayplotlib和seaborn等</li><li>IDE建议使用pycharm，对新手友好，实在是很反感各种新手教学上来就要摸linux配环境的行为，除了加大难度有屁用？</li><li>除了pycharm之外，熟悉ipython的交互形式，最好能够接触到jupyter notebook</li></ul><h3 id="学习方式："><a href="#学习方式：" class="headerlink" title="学习方式："></a>学习方式：</h3><ol><li>对于聪明人，直接看库函数API文档即可，我没有花时间学过python，直接上手写的，用到什么功能什么函数直接百度或者查python的文档即可<ul><li><a href="https://docs.python.org/3.6/" target="_blank" rel="noopener">python3.6 doc</a></li><li><a href="https://matplotlib.org/api/index.html" target="_blank" rel="noopener">matplotlib API</a></li><li><a href="http://scikit-learn.org/stable/documentation.html" target="_blank" rel="noopener">sklearn API</a><br>需要注意的是，在sklearn官网上实在有太多example，配合pycharm使用，可以很快的上手机器学习代码。</li></ul></li><li>对于不聪明的人，可以读一些书，去图书馆搜以下关键词，随便挑一本封面看着比较新的入门就可以了。<ul><li>机器学习实战</li><li>数据分析</li><li>python+数据</li></ul></li><li>推荐使用脑图学习，这也是我最新喜欢的方式，这里使用百度脑图，web打开即用，十分方便：<ul><li><a href="http://naotu.baidu.com/" target="_blank" rel="noopener">百度脑图</a></li></ul></li></ol><h2 id="进阶"><a href="#进阶" class="headerlink" title="进阶"></a>进阶</h2><p>在这个阶段，通过代码上手，我们已经知道了一个基本的机器学习程序流程了：</p><ul><li>数据预处理</li><li>特征分析</li><li>更复杂的数据处理</li><li>丢到机器学习库里</li><li>调整一些参数</li><li>fit一个模型，predict一个结果</li></ul><p>就是这么简单。</p><p>在这个阶段最重要的是搞清楚一些之前很模糊的概念，比如loss，推荐阅读：</p><p><a href="https://blog.csdn.net/u010976453/article/details/78488279" target="_blank" rel="noopener">机器学习中的损失函数 （着重比较：hinge loss vs softmax loss）</a></p><p>比如几个重点模型的推导，简单的知识对应关系如下：</p><ul><li>线性回归逻辑回归  —— 高等数学</li><li>贝叶斯分类 —— 概率论</li><li>神经网络 —— 最优化</li></ul><p>以神经网络为例，最需要搞明白的是梯度下降和反向传播这几个概念，我想如果走到这一步，神经网络的路线也是了然于胸了，从感知器到CNN到RNN到LSTM即可。</p><p>这里也可以参考我的另一篇文章：</p><p><a href="/posts/55073/">面试准备阅读列表</a></p><h2 id="应试"><a href="#应试" class="headerlink" title="应试"></a>应试</h2><p>学习的目的，不是搞科研，发paper，只是为了找工作而已，找工作就要应试，这里建议看七月在线的题目：</p><p><a href="https://www.julyedu.com/question/index" target="_blank" rel="noopener">七月在线题库</a></p><h2 id="比赛"><a href="#比赛" class="headerlink" title="比赛"></a>比赛</h2><p>此外，如果希望做一些比赛，应当从kaggle入手，从最简单的titanic开始即可，有很多人写的kernel（即一些入门教程和示例程序），这里需要有一定的英语水平，其实哪里都需要英语好，英语好了有些问题直接stackoverflow，直接google就好了，很简单。</p><p><a href="https://www.kaggle.com/" target="_blank" rel="noopener">kaggle地址</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;写给师妹的机器学习路线和清单。&lt;/p&gt;
    
    </summary>
    
      <category term="Notes" scheme="https://ykksmile.top/categories/Notes/"/>
    
      <category term="机器学习" scheme="https://ykksmile.top/categories/Notes/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Python" scheme="https://ykksmile.top/tags/Python/"/>
    
      <category term="MachineLearning" scheme="https://ykksmile.top/tags/MachineLearning/"/>
    
  </entry>
  
  <entry>
    <title>华为2018网络大赛超纲内容整理</title>
    <link href="https://ykksmile.top/posts/27479/"/>
    <id>https://ykksmile.top/posts/27479/</id>
    <published>2018-04-20T05:28:46.000Z</published>
    <updated>2018-06-05T11:45:18.491Z</updated>
    
    <content type="html"><![CDATA[<p>2017年在该比赛中获得了西北赛区第二，在此记录一下2018年华为网络大赛可能会出现的超纲知识点，包括云计算、大数据、Docker、微服务等等。</p><a id="more"></a><hr><h2 id="学习视频笔记"><a href="#学习视频笔记" class="headerlink" title="学习视频笔记"></a>学习视频笔记</h2><p>这里是folk的github上2017年有人写的笔记，其中有一定出入，SDN/NFV的内容应该是被删除了。</p><div class="github-widget" data-repo="cloisonne/Huawei-2018-network"></div><h2 id="记录的超纲内容"><a href="#记录的超纲内容" class="headerlink" title="记录的超纲内容"></a>记录的超纲内容</h2><h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h3><p>自动化内存管理(Automatic Memory Management,AMM) </p><ol><li><a href="https://www.cnblogs.com/dato/p/7049343.html" target="_blank" rel="noopener">浅谈 DML、DDL、DCL的区别</a> </li></ol><h4 id="DML、DDL、DCL的区别"><a href="#DML、DDL、DCL的区别" class="headerlink" title="DML、DDL、DCL的区别"></a>DML、DDL、DCL的区别</h4><ul><li>DML（data manipulation language）数据操纵语言</li><li>DDL（data definition language）数据库定义语言</li><li>DCL（Data Control Language）数据库控制语言</li></ul><h4 id="其他知识点"><a href="#其他知识点" class="headerlink" title="其他知识点"></a>其他知识点</h4><ul><li>RMAN对数据库恢复，数据库处于mount状态</li><li>编译SQL 访问共享池</li><li>查询表数据 需要处于open状态</li><li>AMM下，可以自动调整大小的包括 共享池、大型池</li></ul><h3 id="微服务"><a href="#微服务" class="headerlink" title="微服务"></a>微服务</h3><ol><li><a href="https://blog.csdn.net/silencezyn1208/article/details/72236562" target="_blank" rel="noopener">微服务架构浅谈(一)</a> </li><li><a href="https://blog.csdn.net/zeb_perfect/article/details/52536411" target="_blank" rel="noopener">微服务要素-十二要素（The Twelve Factors）</a> </li></ol><ul><li>微服务和单体式应用的区别</li><li>12-factor中的重点<ul><li>基准代码</li><li>依赖</li><li>等等</li></ul></li></ul><h3 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h3><ol><li><a href="http://www.360doc.com/content/16/0421/20/16915_552675362.shtml" target="_blank" rel="noopener">开源大数据处理工具汇总 </a> </li><li><a href="https://www.zhihu.com/question/53331259" target="_blank" rel="noopener">kafka解决了什么问题? </a> </li></ol><ul><li>cloudera的flume，分布式的日志系统</li><li>kafka 是一个分布式的、分区的、多复本的日志提交服务，是一个消息系统。</li><li>zookeeper  是一个分布式的、开放式的分布式应用程序协调服务</li><li>GFS是一个可扩展的分布式文件系统，用于大型的、分布式的、对大量数据进行访问的应用。</li><li>Chubby被设计成为一个需要访问中心化的分布式锁服务。</li><li>BigTable是Google设计的分布式数据存储系统,用来处理海量的数据的一种非关系型的数据库。</li></ul><ol><li><a href="https://blog.csdn.net/zonzereal/article/details/78095110" target="_blank" rel="noopener">hadoop的三大核心组件</a> </li></ol><ul><li>HDFS</li><li>YARN<br>  YARN可以调度的包括Spark Storm MapReduce</li><li>MapReduce</li></ul><h3 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h3><ol><li><a href="https://blog.csdn.net/u013485792/article/details/76071252" target="_blank" rel="noopener">NAPT和NAT的工作原理及其区别</a> </li></ol><p>NAPT 即加端口号 :8888  NAT为IP映射</p><ul><li>虚拟交换机工作在第二层</li><li>在802.1q中,vlan配置的最大可能值为4094 ， 其中0 和 4095保留</li></ul><p><code>Trunk端口既能发送带标签的数据帧，也能发送不带标签的数据帧。</code></p><p>Access端口发往其他设备的报文，都是Untagged数据帧， 而Trunk端口仅在一种特定情况下才能发出untagged数据帧，其它情况发出的都是Tagged数据帧。Hybrid端口是交换机上既可以连接用户主机，又可以连接其他交换机的端口。</p><p>Hybrid端口既可以连接接入链路又可以连接干道链路。Hybrid端口允许多个VLAN的帧通过，并可以在出端口方向将某些VLAN帧的Tag剥掉。华 为设备默认的端口类型是Hybrid。</p><p>Trunk端口收发数据帧的规则如下：</p><ol><li>当接收到对端设备发送的不带Tag的数据帧时，会添加该端口的 PVID，如果PVID在允许通过的VLAN ID列表中，则接收该报文，否则丢 弃该报文。当接收到对端设备发送的带Tag的数据帧时，检查VLANID是 否在允许通过的VLANID列表中。如果VLANID在接口允许通过的VLANID 列表中，则接收该报文。否则丢弃该报文。</li><li>端口发送数据帧时，当VLAN ID与端口的PVID相同，且是该端口允许通 过的VLAN ID时(两个条件)，去掉Tag，发送该报文。<br>当VLANID与端口的PVID不同，且是该端口允许通过的VLANID时，保持原有Tag，发送该报文。</li></ol><h3 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h3><p>停止httpd服务：</p><ul><li>killall httpd</li><li>/etc/init.d/httpd stop</li><li>service httpd stop</li></ul><p>注意，httpd是一个进程组，有子进程，kill不能停止。</p><ul><li>路由表中，有目的地址、下一跳、出接口</li></ul><h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><ol><li><a href="https://blog.csdn.net/mengdonghui123456/article/details/52935486" target="_blank" rel="noopener">docker 三组件：镜像、容器、仓库</a> </li></ol><p>docker的资源控制：</p><ul><li>blkio 输入输出</li><li>cpu cpu</li><li>namespace 隔离</li><li>devices 控制设备访问</li><li>freezer 挂起或恢复</li><li>net-cls 标记网络数据包</li></ul><h3 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h3><p>NAS和SAN的区别</p><ul><li>SAN 本身不自带文件系统，占用客户端资源提供文件系统功能；NAS 本身自 带文件系统 </li><li>SAN 存储通常使用 iSCSI、FC 等协议；NAS 通常使用 NFS、CIFS 等协议 </li><li>NAS 和 SAN 可以整合在同一台存储设备上，即可以实现一台存储产品既用于 SAN，又用于 NAS</li></ul><p>LVM逻辑卷扩展</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2017年在该比赛中获得了西北赛区第二，在此记录一下2018年华为网络大赛可能会出现的超纲知识点，包括云计算、大数据、Docker、微服务等等。&lt;/p&gt;
    
    </summary>
    
      <category term="Notes" scheme="https://ykksmile.top/categories/Notes/"/>
    
      <category term="比赛" scheme="https://ykksmile.top/categories/Notes/%E6%AF%94%E8%B5%9B/"/>
    
    
      <category term="大数据" scheme="https://ykksmile.top/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="云计算" scheme="https://ykksmile.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Docker" scheme="https://ykksmile.top/tags/Docker/"/>
    
      <category term="微服务" scheme="https://ykksmile.top/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>华为2018软件精英挑战赛初赛记录</title>
    <link href="https://ykksmile.top/posts/59415/"/>
    <id>https://ykksmile.top/posts/59415/</id>
    <published>2018-04-16T12:58:36.000Z</published>
    <updated>2018-06-04T12:48:20.268Z</updated>
    
    <content type="html"><![CDATA[<p>2018华为软件精英挑战赛初赛的思路和代码总结。</p><a id="more"></a><hr><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><h3 id="github地址"><a href="#github地址" class="headerlink" title="github地址"></a>github地址</h3><div class="github-widget" data-repo="cloisonne/huawei-2018-software"></div><h3 id="用到的网址"><a href="#用到的网址" class="headerlink" title="用到的网址"></a>用到的网址</h3><p><a href="https://blog.csdn.net/u013719780/article/details/77435158" target="_blank" rel="noopener">手把手教你实现线性回归模型</a></p><p><a href="https://blog.csdn.net/jiede1/article/details/78245597" target="_blank" rel="noopener">机器学习算法—随机森林实现（包括回归和分类）</a></p><p><a href="https://blog.csdn.net/ppp8300885/article/details/77934822" target="_blank" rel="noopener">新手向的时间序列预测解决方案-前Top2%</a></p><hr><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><h3 id="stacking"><a href="#stacking" class="headerlink" title="stacking"></a>stacking</h3><p>主要采用模型堆叠，stacking的方式，stack了包括拉格朗日均值、随机森林回归、线性回归、指数平滑等算法，利用本地调试脚本，进行参数优化。</p><h3 id="序列预测的平滑处理"><a href="#序列预测的平滑处理" class="headerlink" title="序列预测的平滑处理"></a>序列预测的平滑处理</h3><p>包括均值化、归一化、差分、滑动窗口。</p><h3 id="装箱算法"><a href="#装箱算法" class="headerlink" title="装箱算法"></a>装箱算法</h3><p>实现了包括首次适应、多重背包、模拟退火等。</p><hr><h2 id="失败原因"><a href="#失败原因" class="headerlink" title="失败原因"></a>失败原因</h2><h3 id="华为的问题"><a href="#华为的问题" class="headerlink" title="华为的问题"></a>华为的问题</h3><ul><li>高级测试用例格式与初级不符，浪费2次机会</li><li>规定时间60s不区分语言，python直接跑超时，浪费5次机会</li></ul><h3 id="自己的问题"><a href="#自己的问题" class="headerlink" title="自己的问题"></a>自己的问题</h3><ul><li>代码的优化不好，事实上模拟退火本地应该做一个60s的测试，测最大数据量</li><li>stack过多，这种比赛，模型越简单越容易</li><li>调参大赛，前期关注在初赛刷榜，关注点有问题</li><li>python没有numpy等第三方库，实现一些算法很麻烦，效率又低</li></ul><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2018华为软件精英挑战赛初赛的思路和代码总结。&lt;/p&gt;
    
    </summary>
    
      <category term="Notes" scheme="https://ykksmile.top/categories/Notes/"/>
    
    
      <category term="Python" scheme="https://ykksmile.top/tags/Python/"/>
    
      <category term="MachineLearning" scheme="https://ykksmile.top/tags/MachineLearning/"/>
    
  </entry>
  
  <entry>
    <title>C程序在linux下的segmentation-fault（core-dumped）</title>
    <link href="https://ykksmile.top/posts/38716/"/>
    <id>https://ykksmile.top/posts/38716/</id>
    <published>2018-04-16T12:46:32.000Z</published>
    <updated>2018-06-04T12:48:20.282Z</updated>
    
    <content type="html"><![CDATA[<p>调试程序过程中出现core dumped，各种原因项目无法导入eclipse，只能使用gbd进行调试。</p><a id="more"></a><hr><h3 id="Segmentation-fault-core-dumped-原因"><a href="#Segmentation-fault-core-dumped-原因" class="headerlink" title="Segmentation fault (core dumped)原因"></a>Segmentation fault (core dumped)原因</h3><p>Segmentation fault (core dumped)多为内存不当操作造成。空指针、野指针的读写操作，数组越界访问，破坏常量等。</p><hr><h3 id="使用gdb查看core文件"><a href="#使用gdb查看core文件" class="headerlink" title="使用gdb查看core文件"></a>使用gdb查看core文件</h3><p>设置core文件大小：</p><pre><code>ulimit -aulimit -c unlimited</code></pre><p>gdb查看core文件:</p><pre><code>gdb ./file core</code></pre><hr><h3 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h3><blockquote><p>输入start使程序运行到main中第一行运行代码。next或者n为执行下一行程序，until xx执行到xx行，print或p可输出变量值，b xx用于在xx行设置断点，run或r用于执行程序至下一断点，d xx删除xx行断点。<br>我们可以先run一遍程序，这时它会提示出错行信息。然后until到出错行前5行，交替执行next和print，输出与出错行变量相关变量或指针的值。最终定位出错的根本操作在哪一行。修改之即可。</p></blockquote><hr><h3 id="出错原因"><a href="#出错原因" class="headerlink" title="出错原因"></a>出错原因</h3><p>数组越界，写C语言的过程中一定要密切关注数组越界问题。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#0  0x0000000000405ef0 in get_operator (fd=10, stateinfo=0x679c00 &lt;stateinfo&gt;)</span><br><span class="line">    at SIM_wifi_state.c:247</span><br><span class="line"></span><br><span class="line">warning: Source file is more recent than executable.</span><br><span class="line">247while(buff[i+1]!=&apos;\&quot;&apos;)</span><br><span class="line">[Current thread is 1 (Thread 0x7f784ff96700 (LWP 10051))]</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;调试程序过程中出现core dumped，各种原因项目无法导入eclipse，只能使用gbd进行调试。&lt;/p&gt;
    
    </summary>
    
      <category term="Notes" scheme="https://ykksmile.top/categories/Notes/"/>
    
    
      <category term="Linux" scheme="https://ykksmile.top/tags/Linux/"/>
    
      <category term="C" scheme="https://ykksmile.top/tags/C/"/>
    
  </entry>
  
</feed>
