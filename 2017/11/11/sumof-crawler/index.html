<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Python爬虫总结（附拉勾网多进程代理池爬虫）"><meta name="keywords" content="Python,爬虫"><meta name="author" content="John Doe,undefined"><meta name="copyright" content="John Doe"><title>Python爬虫总结（附拉勾网多进程代理池爬虫） | Hexo</title><link rel="shortcut icon" href="/favicon.ico"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css?version=1.5.4"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><link rel="dns-prefetch" href="https://unpkg.com"><link rel="stylesheet" type="text/css" href="https://unpkg.com/gitment@latest/style/default.css"><script src="https://unpkg.com/gitment@latest/dist/gitment.browser.js"></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  localSearch: {"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}"},"path":"search.xml"}
} </script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#intro"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#写过的东西"><span class="toc-number">1.1.</span> <span class="toc-text">写过的东西</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#拉勾网爬虫"><span class="toc-number">1.2.</span> <span class="toc-text">拉勾网爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#断点续传的实现方式："><span class="toc-number">1.2.1.</span> <span class="toc-text">断点续传的实现方式：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#多进程使用Pool进程池："><span class="toc-number">1.2.2.</span> <span class="toc-text">多进程使用Pool进程池：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#代理测试使用telnet方法："><span class="toc-number">1.2.3.</span> <span class="toc-text">代理测试使用telnet方法：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#数据库计数器实时监测："><span class="toc-number">1.2.4.</span> <span class="toc-text">数据库计数器实时监测：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#高级爬虫技术总结"><span class="toc-number">1.3.</span> <span class="toc-text">高级爬虫技术总结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#未来工作"><span class="toc-number">1.4.</span> <span class="toc-text">未来工作</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="http://p9ss48mfk.bkt.clouddn.com/avatar.jpg"></div><div class="author-info__name text-center">John Doe</div><div class="author-info__description text-center"></div><div class="follow-button"><a href="https://github.com/cloisonne" target="_blank">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">41</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">35</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">4</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(http://p9ss48mfk.bkt.clouddn.com/bg-5.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Hexo</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">Python爬虫总结（附拉勾网多进程代理池爬虫）</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2017-11-11</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Codes/">Codes</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">485</span><span class="post-meta__separator">|</span><span>Reading time: 2 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div id="post-content"><p></p><h2 id="intro">前言</h2>一直秉承增量学习的策略，写了一些爬虫，还没有到需要scrapy的地步，爬取拉勾网遇到了瓶颈，因为反爬策略比较强，在此总结。<p></p>
<a id="more"></a>
<hr>
<h3 id="写过的东西"><a href="#写过的东西" class="headerlink" title="写过的东西"></a>写过的东西</h3><p>最近写的都放在了gayhub上：</p>
<div class="github-widget" data-repo="cloisonne/Show-me-the-code_Python"></div>

<p>包括有：<code>获取代理池</code>、<code>爬取bing图片</code>等等。</p>
<h3 id="拉勾网爬虫"><a href="#拉勾网爬虫" class="headerlink" title="拉勾网爬虫"></a>拉勾网爬虫</h3><p>分为以下步骤：</p>
<ul>
<li>获取所有板块url，存入mongoDB</li>
<li>在所需的url中，爬取所有的工作链接url，存入mongoDB</li>
<li>断点续传，多进程爬取所有储存的url中的信息，存入mongoDB</li>
<li>数据分析（待完成）</li>
</ul>
<p>其中</p>
<h4 id="断点续传的实现方式："><a href="#断点续传的实现方式：" class="headerlink" title="断点续传的实现方式："></a>断点续传的实现方式：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">db_url = [i[<span class="string">'url'</span>] <span class="keyword">for</span> i <span class="keyword">in</span> url_list.find()]</span><br><span class="line">recent_url = [j[<span class="string">'url'</span>] <span class="keyword">for</span> j <span class="keyword">in</span> job_info.find()]</span><br><span class="line">x = set(db_url)</span><br><span class="line">y = set(recent_url)</span><br><span class="line">rest_of_urls = x-y</span><br></pre></td></tr></table></figure>
<h4 id="多进程使用Pool进程池："><a href="#多进程使用Pool进程池：" class="headerlink" title="多进程使用Pool进程池："></a>多进程使用Pool进程池：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cookies = login_lagou()</span><br><span class="line">pool = Pool(processes=<span class="number">4</span>)</span><br><span class="line">pool.apply_async(get_all_job_info(rest_of_urls,cookies))</span><br><span class="line">print(len(rest_of_urls))</span><br><span class="line"><span class="comment"># pool.apply_async(get_all_links_from(channel,cookies))</span></span><br><span class="line">pool.close()</span><br><span class="line">pool.join()</span><br></pre></td></tr></table></figure>
<h4 id="代理测试使用telnet方法："><a href="#代理测试使用telnet方法：" class="headerlink" title="代理测试使用telnet方法："></a>代理测试使用telnet方法：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_link</span><span class="params">(ip,_port)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        telnetlib.Telnet(ip, port=_port, timeout=<span class="number">5</span>)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'connect failed'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'success'</span>)</span><br></pre></td></tr></table></figure>
<h4 id="数据库计数器实时监测："><a href="#数据库计数器实时监测：" class="headerlink" title="数据库计数器实时监测："></a>数据库计数器实时监测：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    print(job_info.find().count())</span><br><span class="line">    time.sleep(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="高级爬虫技术总结"><a href="#高级爬虫技术总结" class="headerlink" title="高级爬虫技术总结"></a>高级爬虫技术总结</h3><p><strong>高端反爬技巧</strong>：</p>
<ul>
<li>校验 User-Agent（没用）</li>
<li>图片假链（人点不到，爬虫必中）</li>
<li>阶梯访问量控制</li>
</ul>
<blockquote>
<p>基于访问数量，人类的访问一般集中在短时间内大部分网页，爬虫是线性增长，可设置短期策略和长期策略识别非人类。</p>
</blockquote>
<p><strong>常见的反反爬技巧</strong>：</p>
<ul>
<li>User-Agent池</li>
<li>Referer保持</li>
<li>代理池</li>
<li>图像识别验证码</li>
<li>登陆状态cookies保持</li>
<li>多账号反爬</li>
<li>分布式爬虫</li>
<li>selenium</li>
</ul>
<hr>
<h3 id="未来工作"><a href="#未来工作" class="headerlink" title="未来工作"></a>未来工作</h3><p>重心主要在数据分析和机器学习上，爬虫如果再有接触的话，应当写一个自己的fetcher类，糅合代理、多线程、异步IO、断点续传等功能。</p>
<p>参考<a href="http://outofmemory.cn/code-snippet/1653/python-pachong-zhua-wangye-summary" target="_blank" rel="noopener">python爬虫抓网页的总结</a></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">John Doe</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yoursite.com/2017/11/11/sumof-crawler/">http://yoursite.com/2017/11/11/sumof-crawler/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/爬虫/">爬虫</a></div><div class="social-share" data-disabled="google,facebook,twitter"></div><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2017/12/15/kaggle-titanic/"><i class="fa fa-chevron-left">  </i><span>针对Titanic问题的各种分类器stacking和XGBoost解法</span></a></div><div class="next-post pull-right"><a href="/2017/11/02/get-ruisi-pictures/"><span>睿思图片爬取实战（附代码）</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="gitment-container"></div><script>var gitment = new Gitment({
  owner: 'cloisonne',
  repo: 'cloisonne.github.io',
  oauth: {
    client_id: 'd6cdb36f97d08963e9cc',
    client_secret: '32f854846bf95d283ee654337570bbed41f69f03'
  }
})
gitment.render('gitment-container')</script></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2016 - 2018 By John Doe</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.5.4"></script><script src="/js/fancybox.js?version=1.5.4"></script><script src="/js/sidebar.js?version=1.5.4"></script><script src="/js/copy.js?version=1.5.4"></script><script src="/js/fireworks.js?version=1.5.4"></script><script src="/js/transition.js?version=1.5.4"></script><script src="/js/scroll.js?version=1.5.4"></script><script src="/js/head.js?version=1.5.4"></script></body></html>